{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "27226166",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import shutil\n",
    "import subprocess\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import torch\n",
    "import torchaudio\n",
    "def normalize_volumes(volumes):\n",
    "    \"\"\"\n",
    "    Normalizes the volumes to the range [0, 1] for each volume independently in the batch across all frames.\n",
    "\n",
    "    Args:\n",
    "        volumes: Tensor of shape (B, T, H, W) representing the volumes.\n",
    "\n",
    "    Returns:\n",
    "        normalized_volumes: Tensor of the same shape as input, normalized to [0, 1].\n",
    "    \"\"\"\n",
    "    # Compute min and max for each volume independently (across all T, H, W)\n",
    "    min_vals = volumes.reshape(volumes.shape[0], -1).min(dim=1, keepdim=True)[0]  # Shape: [B, 1]\n",
    "    max_vals = volumes.reshape(volumes.shape[0], -1).max(dim=1, keepdim=True)[0]  # Shape: [B, 1]\n",
    "\n",
    "    # Reshape for broadcasting\n",
    "    min_vals = min_vals.view(-1, 1, 1, 1)  # Shape: [B, 1, 1, 1]\n",
    "    max_vals = max_vals.view(-1, 1, 1, 1)  # Shape: [B, 1, 1, 1]\n",
    "\n",
    "    # Handle edge case where min equals max (flat volume)\n",
    "    epsilon = 1e-8\n",
    "    divisor = torch.clamp(max_vals - min_vals, min=epsilon)\n",
    "\n",
    "    # Normalize each volume to [0, 1] range (across all frames)\n",
    "    normalized_volumes = (volumes - min_vals) / divisor\n",
    "    return normalized_volumes\n",
    "\n",
    "class MatchmapVideoGeneratorDenseAV:\n",
    "    def __init__(self,model, device, img, audio_path,  matchmap_path = None):\n",
    "        self.model = model\n",
    "        self.device = device\n",
    "        self.audio_waveform, self.sample_rate = torchaudio.load(audio_path)\n",
    "        self.image = img.unsqueeze(0).to(device)  # Add batch dimension and move to device\n",
    "        #image [b,c,h,w] but for DenseAV it is[k,b,c,h,w] k for head\n",
    "\n",
    "        if matchmap_path is not None:\n",
    "            self.matchmap = torch.load(matchmap_path, map_location=device)\n",
    "        else:\n",
    "            self.matchmap = None\n",
    "        self.audio_length = self.audio_waveform.shape[1] / self.sample_rate\n",
    "        print(f\"Audio length in seconds: {self.audio_length:.2f}\")\n",
    "        self.video = None\n",
    "\n",
    "\n",
    "    def compute_matchmap(self):\n",
    "        with torch.no_grad():\n",
    "            aud_feats = self.model.forward_audio({\"audio\": self.audio_waveform.cpu()})\n",
    "            aud_feats = {k: v.cpu() for k, v in aud_feats.items()}\n",
    "            print(f\"Extracted audio_feats['audio_feats'] tensor shape: {aud_feats['audio_feats'].shape}\")\n",
    "\n",
    "            img_feats = self.model.forward_image({\"frames\": self.image.unsqueeze(0).cpu()}, max_batch_size=1)\n",
    "            img_feats = {k: v.cpu() for k,v in img_feats.items()}\n",
    "            print(f\"Extracted image_feats['image_feats'] tensor shape: {img_feats['image_feats'].shape}\")\n",
    "\n",
    "            aud_emb = aud_feats['audio_feats'].squeeze(2).squeeze(0)  # [c, t]\n",
    "            img_emb = img_feats['image_feats'].squeeze(0)\n",
    "            self.matchmap = torch.einsum('ct, chw -> thw',aud_emb,img_emb)\n",
    "            print(f\"Computed matchmap tensor shape: {self.matchmap.shape}\")\n",
    "            print(f\"Number of simframes/sec : {self.matchmap.shape[0] / self.audio_length:.2f}\")\n",
    "        return self.matchmap\n",
    "    \n",
    "    def normalize_img(self, value, vmax=None, vmin=None):\n",
    "        '''\n",
    "        Normalize heatmap\n",
    "        '''\n",
    "        vmin = value.min() if vmin is None else vmin\n",
    "        vmax = value.max() if vmax is None else vmax\n",
    "        if not (vmax - vmin) == 0:\n",
    "            value = (value - vmin) / (vmax - vmin)  # vmin..vmax\n",
    "        return value\n",
    "    \n",
    "    def get_frame_match(self, img_np, matchmap_np, frame_idx):\n",
    "        assert img_np.ndim == 3, \"img_np should be a 3D numpy array\"\n",
    "        assert matchmap_np.ndim == 3, \"matchmap_np should be a 3D numpy array\"\n",
    "\n",
    "        matchmap_i = matchmap_np[frame_idx]\n",
    "        matchmap_i = cv2.resize(matchmap_i, dsize=(224, 224), interpolation=cv2.INTER_LINEAR)\n",
    "        # if self.args.normalize_volumes_thw:\n",
    "        #     pass\n",
    "        # else:\n",
    "        #     matchmap_i = self.normalize_img(matchmap_i)\n",
    "        matchmap_i_photo = (matchmap_i * 255).astype(np.uint8)\n",
    "        matchmap_i_photo = cv2.applyColorMap(matchmap_i_photo, cv2.COLORMAP_JET)\n",
    "        matchmap_i_photo = cv2.addWeighted(matchmap_i_photo, 0.5, img_np, 0.5, 0)\n",
    "        return matchmap_i_photo\n",
    "    \n",
    "    def create_video_f(self,img_np, matchmap_np, output_path=\"matchmap_video.mp4\", fps=1):\n",
    "        n_frames = matchmap_np.shape[0]\n",
    "        \n",
    "        # Make sure img_np is in uint8 format\n",
    "        if img_np.dtype != np.uint8:\n",
    "            img_np = (img_np * 255).astype(np.uint8)\n",
    "        \n",
    "        # Make sure img_np has correct dimensions (224, 224, 3)\n",
    "        if img_np.shape[:2] != (224, 224):\n",
    "            img_np = cv2.resize(img_np, (224, 224))\n",
    "        \n",
    "        # Use proper codec for compatibility\n",
    "        # For better compatibility, try 'avc1' or 'H264' instead of 'mp4v'\n",
    "        fourcc = cv2.VideoWriter_fourcc(*'MP4V') \n",
    "        \n",
    "        # Alternative codec options if 'avc1' doesn't work:\n",
    "        # fourcc = cv2.VideoWriter_fourcc(*'H264')\n",
    "        # fourcc = cv2.VideoWriter_fourcc(*'XVID')  # More compatible but lower quality\n",
    "        \n",
    "        out = cv2.VideoWriter(output_path, fourcc, fps, (224, 224))\n",
    "        \n",
    "        if not out.isOpened():\n",
    "            print(\"Failed to create VideoWriter. Trying alternative codec...\")\n",
    "            # Try with different codec\n",
    "            fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "            out = cv2.VideoWriter(output_path.replace('.mp4', '.avi'), fourcc, fps, (224, 224))\n",
    "        \n",
    "        for i in range(n_frames):\n",
    "            frame = self.get_frame_match(img_np, matchmap_np, i)\n",
    "            \n",
    "            # Ensure frame is the correct format\n",
    "            if frame.dtype != np.uint8:\n",
    "                frame = (frame * 255).astype(np.uint8)\n",
    "                \n",
    "            # Ensure frame has the right shape\n",
    "            if frame.shape[:2] != (224, 224):\n",
    "                frame = cv2.resize(frame, (224, 224))\n",
    "                \n",
    "            # Verify frame is BGR (OpenCV's default format)\n",
    "            if len(frame.shape) == 3 and frame.shape[2] == 3:\n",
    "                out.write(frame)\n",
    "            else:\n",
    "                print(f\"Warning: Frame {i} has incorrect format. Shape: {frame.shape}\")\n",
    "        \n",
    "        out.release()\n",
    "        print(f\"Video created at: {output_path}\")\n",
    "        \n",
    "        # Verify the file was created and has a non-zero size\n",
    "        if os.path.exists(output_path) and os.path.getsize(output_path) > 0:\n",
    "            print(f\"Success! Video file created: {os.path.getsize(output_path)} bytes\")\n",
    "        else:\n",
    "            print(\"Error: Video file was not created properly\")\n",
    "            \n",
    "\n",
    "    def create_video(self,output_path):\n",
    "        img_np = self.image[0].cpu().numpy()\n",
    "        img_np = np.transpose(img_np, (1, 2, 0))\n",
    "        img_np = self.normalize_img(img_np)\n",
    "        img_np = (img_np * 255).astype(np.uint8)\n",
    "        img_np = cv2.cvtColor(img_np, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "        if self.matchmap is None:\n",
    "            self.matchmap = self.compute_matchmap()\n",
    "        \n",
    "        # if self.args.normalize_volumes_thw:\n",
    "        self.matchmap = normalize_volumes(self.matchmap.unsqueeze(0))\n",
    "        self.matchmap = self.matchmap.squeeze(0)\n",
    "\n",
    "        matchmap_np = self.matchmap.cpu().numpy()\n",
    "        n_frames = matchmap_np.shape[0]\n",
    "        self.create_video_f(img_np, matchmap_np, output_path, fps=n_frames/ self.audio_length) \n",
    "\n",
    "\n",
    "    def add_audio_to_video(self, video_path, audio_path):\n",
    "        \"\"\"\n",
    "        Add audio to video using ffmpeg and overwrite the output file if it exists.\n",
    "        \"\"\"\n",
    "        temp_output = \"temp_output.mp4\"\n",
    "        \n",
    "        # Ensure the audio file exists\n",
    "        if not os.path.exists(audio_path):\n",
    "            raise Exception(\"Error: Audio file not found.\")\n",
    "\n",
    "        # Use ffmpeg to merge audio and video\n",
    "        command = [\n",
    "            \"ffmpeg\",\n",
    "            \"-y\",  # Overwrite output files without asking\n",
    "            \"-i\", video_path,  # Input video\n",
    "            # \"-stream_loop\", \"-1\",  # Infinite loop for audio\n",
    "            \"-i\", audio_path,  # Input audio\n",
    "            \"-map\", \"0:v\",  # Video stream from first input\n",
    "            \"-map\", \"1:a\",  # Audio stream from second input\n",
    "            \"-c:v\", \"copy\",  # Copy video codec (no re-encoding)\n",
    "            \"-c:a\", \"libmp3lame\",  # Encode audio in mp3 format\n",
    "            temp_output\n",
    "        ]\n",
    "        \n",
    "        try:\n",
    "            subprocess.run(command, stdout=subprocess.DEVNULL, stderr=subprocess.PIPE, check=True)\n",
    "            if os.path.exists(temp_output):  # Ensure the temporary file exists\n",
    "                os.remove(video_path)  # Delete the original video file\n",
    "                shutil.move(temp_output, video_path)  # Rename the temporary file\n",
    "            else:\n",
    "                raise Exception(\"Error: Temporary output file not created.\")\n",
    "        except subprocess.CalledProcessError as e:\n",
    "            raise Exception(f\"Error during ffmpeg execution: {e.stderr.decode('utf-8')}\")\n",
    "\n",
    "    def create_video_with_audio(self, output_path, audio_path):\n",
    "        self.create_video(output_path)\n",
    "        self.add_audio_to_video(output_path, audio_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ffabf977",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/upftfg03/asantos/.conda/envs/ag-118/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image tensor shape: torch.Size([3, 224, 224])\n",
      "Using device: cpu\n",
      "Audio length in seconds: 7.89\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OpenCV: FFMPEG: tag 0x5634504d/'MP4V' is not supported with codec id 12 and format 'mp4 / MP4 (MPEG-4 Part 14)'\n",
      "OpenCV: FFMPEG: fallback to use tag 0x7634706d/'mp4v'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video created at: matchmap_denseav.mp4\n",
      "Success! Video file created: 233274 bytes\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import utils.util as u\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "json_file = os.path.expandvars('$DATA/PlacesAudio_400k_distro/metadata/val.json')\n",
    "gs = u.GetSampleFromJson(json_file, local_dir=\"/home/asantos/code/DenseAV/denseav.egg-info\", padvalue=0)\n",
    "image_path, audio_path = gs.get_sample(23)\n",
    "image = gs.load_image(image_path)\n",
    "print(f\"image tensor shape: {image.shape}\")\n",
    "\n",
    "#use the class to compute matchmap\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "matchmap_generator = MatchmapVideoGeneratorDenseAV(model=None, device=device, img=image, audio_path=audio_path, matchmap_path=\"matchmap.pt\")\n",
    "matchmap_generator.create_video_with_audio(output_path=\"matchmap_denseav.mp4\", audio_path=audio_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "468a243c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
