{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate video given a model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# To get the videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference already in local\n",
      "Inference already in local\n",
      "Inference already in local\n",
      "Inference already in local\n",
      "Inference already in local\n",
      "Proceed to make the inference\n",
      "The model is in local\n",
      "-Model Loaded\n",
      "Sample already downloaded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/albert/UPF/SSL-TIE_TFG/utils/util.py:772: FutureWarning: Pass sr=16000, n_fft=400 as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel_basis = librosa.filters.mel(sr, n_fft, n_mels=num_mel_bins, fmin=fmin)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video created at: dir_exp_PlacesAudio/inferences/14/mm_SSL_TIE_PlacesAudio-lr1e-4-B128-SISA-SdT128-epoch33_val_14.mp4\n",
      "Success! Video file created: 125430 bytes\n",
      "Proceed to make the inference\n",
      "The model is in local\n",
      "-Model Loaded\n",
      "Sample already downloaded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/albert/UPF/SSL-TIE_TFG/utils/util.py:772: FutureWarning: Pass sr=16000, n_fft=400 as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel_basis = librosa.filters.mel(sr, n_fft, n_mels=num_mel_bins, fmin=fmin)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video created at: dir_exp_PlacesAudio/inferences/14/mm_SSL_TIE_PlacesAudio-lr1e-4-B128-SISA-SdT128-epoch20_val_14.mp4\n",
      "Success! Video file created: 125958 bytes\n",
      "Proceed to make the inference\n",
      "The model is in local\n",
      "-Model Loaded\n",
      "Sample already downloaded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/albert/UPF/SSL-TIE_TFG/utils/util.py:772: FutureWarning: Pass sr=16000, n_fft=400 as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel_basis = librosa.filters.mel(sr, n_fft, n_mels=num_mel_bins, fmin=fmin)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video created at: dir_exp_PlacesAudio/inferences/14/mm_SSL_TIE_PlacesAudio-lr1e-4-B128-S2Ms1571-SdT128-epoch20_val_14.mp4\n",
      "Success! Video file created: 87639 bytes\n",
      "Proceed to make the inference\n",
      "The model is in local\n",
      "-Model Loaded\n",
      "Sample already downloaded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/albert/UPF/SSL-TIE_TFG/utils/util.py:772: FutureWarning: Pass sr=16000, n_fft=400 as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel_basis = librosa.filters.mel(sr, n_fft, n_mels=num_mel_bins, fmin=fmin)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video created at: dir_exp_PlacesAudio/inferences/14/mm_SSL_TIE_PlacesAudio-lr1e-4-B128-S2Ms1571-SdT128-epoch40_val_14.mp4\n",
      "Success! Video file created: 93547 bytes\n",
      "Proceed to make the inference\n",
      "The model is in local\n",
      "-Model Loaded\n",
      "Sample already downloaded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/albert/UPF/SSL-TIE_TFG/utils/util.py:772: FutureWarning: Pass sr=16000, n_fft=400 as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel_basis = librosa.filters.mel(sr, n_fft, n_mels=num_mel_bins, fmin=fmin)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video created at: dir_exp_PlacesAudio/inferences/14/mm_SSL_TIE_PlacesAudio-lr1e-4-B128-S2Ms1571-SdT128-epoch51_val_14.mp4\n",
      "Success! Video file created: 95356 bytes\n",
      "Proceed to make the inference\n",
      "The model is in local\n",
      "-Model Loaded\n",
      "Sample already downloaded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/albert/UPF/SSL-TIE_TFG/utils/util.py:772: FutureWarning: Pass sr=16000, n_fft=400 as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel_basis = librosa.filters.mel(sr, n_fft, n_mels=num_mel_bins, fmin=fmin)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video created at: dir_exp_PlacesAudio/inferences/20/mm_SSL_TIE_PlacesAudio-lr1e-4-B128-SISA-SdT128-epoch33_val_20.mp4\n",
      "Success! Video file created: 141106 bytes\n",
      "Proceed to make the inference\n",
      "The model is in local\n",
      "-Model Loaded\n",
      "Sample already downloaded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/albert/UPF/SSL-TIE_TFG/utils/util.py:772: FutureWarning: Pass sr=16000, n_fft=400 as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel_basis = librosa.filters.mel(sr, n_fft, n_mels=num_mel_bins, fmin=fmin)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video created at: dir_exp_PlacesAudio/inferences/20/mm_SSL_TIE_PlacesAudio-lr1e-4-B128-SISA-SdT128-epoch20_val_20.mp4\n",
      "Success! Video file created: 152149 bytes\n",
      "Proceed to make the inference\n",
      "The model is in local\n",
      "-Model Loaded\n",
      "Sample already downloaded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/albert/UPF/SSL-TIE_TFG/utils/util.py:772: FutureWarning: Pass sr=16000, n_fft=400 as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel_basis = librosa.filters.mel(sr, n_fft, n_mels=num_mel_bins, fmin=fmin)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video created at: dir_exp_PlacesAudio/inferences/20/mm_SSL_TIE_PlacesAudio-lr1e-4-B128-S2Ms1571-SdT128-epoch20_val_20.mp4\n",
      "Success! Video file created: 104951 bytes\n",
      "Proceed to make the inference\n",
      "The model is in local\n",
      "-Model Loaded\n",
      "Sample already downloaded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/albert/UPF/SSL-TIE_TFG/utils/util.py:772: FutureWarning: Pass sr=16000, n_fft=400 as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel_basis = librosa.filters.mel(sr, n_fft, n_mels=num_mel_bins, fmin=fmin)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video created at: dir_exp_PlacesAudio/inferences/20/mm_SSL_TIE_PlacesAudio-lr1e-4-B128-S2Ms1571-SdT128-epoch40_val_20.mp4\n",
      "Success! Video file created: 117573 bytes\n",
      "Proceed to make the inference\n",
      "The model is in local\n",
      "-Model Loaded\n",
      "Sample already downloaded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/albert/UPF/SSL-TIE_TFG/utils/util.py:772: FutureWarning: Pass sr=16000, n_fft=400 as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel_basis = librosa.filters.mel(sr, n_fft, n_mels=num_mel_bins, fmin=fmin)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video created at: dir_exp_PlacesAudio/inferences/20/mm_SSL_TIE_PlacesAudio-lr1e-4-B128-S2Ms1571-SdT128-epoch51_val_20.mp4\n",
      "Success! Video file created: 97458 bytes\n",
      "Proceed to make the inference\n",
      "The model is in local\n",
      "-Model Loaded\n",
      "Sample NOT in dir_exp_PlacesAudio \n",
      "-> download  \n",
      "['scp', '-P', '2122', 'asantos@pirineus3.csuc.cat:/data/upftfg03/asantos/PlacesAudio_400k_distro/images256/c/classroom/gsun_3d1f6ddb82b9068765ca55a43051ad3b.jpg', 'dir_exp_PlacesAudio/frame']\n",
      "['scp', '-P', '2122', 'asantos@pirineus3.csuc.cat:/data/upftfg03/asantos/PlacesAudio_400k_distro/wavs/12/utterance_89791.wav', 'dir_exp_PlacesAudio/audio']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/albert/UPF/SSL-TIE_TFG/utils/util.py:772: FutureWarning: Pass sr=16000, n_fft=400 as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel_basis = librosa.filters.mel(sr, n_fft, n_mels=num_mel_bins, fmin=fmin)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video created at: dir_exp_PlacesAudio/inferences/26/mm_SSL_TIE_PlacesAudio-lr1e-4-B128-SISA-SdT128-epoch33_val_26.mp4\n",
      "Success! Video file created: 178433 bytes\n",
      "Proceed to make the inference\n",
      "The model is in local\n",
      "-Model Loaded\n",
      "Sample already downloaded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/albert/UPF/SSL-TIE_TFG/utils/util.py:772: FutureWarning: Pass sr=16000, n_fft=400 as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel_basis = librosa.filters.mel(sr, n_fft, n_mels=num_mel_bins, fmin=fmin)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video created at: dir_exp_PlacesAudio/inferences/26/mm_SSL_TIE_PlacesAudio-lr1e-4-B128-SISA-SdT128-epoch20_val_26.mp4\n",
      "Success! Video file created: 181435 bytes\n",
      "Proceed to make the inference\n",
      "The model is in local\n",
      "-Model Loaded\n",
      "Sample already downloaded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/albert/UPF/SSL-TIE_TFG/utils/util.py:772: FutureWarning: Pass sr=16000, n_fft=400 as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel_basis = librosa.filters.mel(sr, n_fft, n_mels=num_mel_bins, fmin=fmin)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video created at: dir_exp_PlacesAudio/inferences/26/mm_SSL_TIE_PlacesAudio-lr1e-4-B128-S2Ms1571-SdT128-epoch20_val_26.mp4\n",
      "Success! Video file created: 141766 bytes\n",
      "Proceed to make the inference\n",
      "The model is in local\n",
      "-Model Loaded\n",
      "Sample already downloaded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/albert/UPF/SSL-TIE_TFG/utils/util.py:772: FutureWarning: Pass sr=16000, n_fft=400 as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel_basis = librosa.filters.mel(sr, n_fft, n_mels=num_mel_bins, fmin=fmin)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video created at: dir_exp_PlacesAudio/inferences/26/mm_SSL_TIE_PlacesAudio-lr1e-4-B128-S2Ms1571-SdT128-epoch40_val_26.mp4\n",
      "Success! Video file created: 180849 bytes\n",
      "Proceed to make the inference\n",
      "The model is in local\n",
      "-Model Loaded\n",
      "Sample already downloaded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/albert/UPF/SSL-TIE_TFG/utils/util.py:772: FutureWarning: Pass sr=16000, n_fft=400 as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel_basis = librosa.filters.mel(sr, n_fft, n_mels=num_mel_bins, fmin=fmin)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video created at: dir_exp_PlacesAudio/inferences/26/mm_SSL_TIE_PlacesAudio-lr1e-4-B128-S2Ms1571-SdT128-epoch51_val_26.mp4\n",
      "Success! Video file created: 187452 bytes\n",
      "Proceed to make the inference\n",
      "The model is in local\n",
      "-Model Loaded\n",
      "Sample NOT in dir_exp_PlacesAudio \n",
      "-> download  \n",
      "['scp', '-P', '2122', 'asantos@pirineus3.csuc.cat:/data/upftfg03/asantos/PlacesAudio_400k_distro/images256/b/butchers_shop/gsun_d35ae4ad92b94c700b993b976f348b69.jpg', 'dir_exp_PlacesAudio/frame']\n",
      "['scp', '-P', '2122', 'asantos@pirineus3.csuc.cat:/data/upftfg03/asantos/PlacesAudio_400k_distro/wavs/186/utterance_258559.wav', 'dir_exp_PlacesAudio/audio']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/albert/UPF/SSL-TIE_TFG/utils/util.py:772: FutureWarning: Pass sr=16000, n_fft=400 as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel_basis = librosa.filters.mel(sr, n_fft, n_mels=num_mel_bins, fmin=fmin)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video created at: dir_exp_PlacesAudio/inferences/200/mm_SSL_TIE_PlacesAudio-lr1e-4-B128-SISA-SdT128-epoch33_val_200.mp4\n",
      "Success! Video file created: 107801 bytes\n",
      "Proceed to make the inference\n",
      "The model is in local\n",
      "-Model Loaded\n",
      "Sample already downloaded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/albert/UPF/SSL-TIE_TFG/utils/util.py:772: FutureWarning: Pass sr=16000, n_fft=400 as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel_basis = librosa.filters.mel(sr, n_fft, n_mels=num_mel_bins, fmin=fmin)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video created at: dir_exp_PlacesAudio/inferences/200/mm_SSL_TIE_PlacesAudio-lr1e-4-B128-SISA-SdT128-epoch20_val_200.mp4\n",
      "Success! Video file created: 116780 bytes\n",
      "Proceed to make the inference\n",
      "The model is in local\n",
      "-Model Loaded\n",
      "Sample already downloaded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/albert/UPF/SSL-TIE_TFG/utils/util.py:772: FutureWarning: Pass sr=16000, n_fft=400 as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel_basis = librosa.filters.mel(sr, n_fft, n_mels=num_mel_bins, fmin=fmin)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video created at: dir_exp_PlacesAudio/inferences/200/mm_SSL_TIE_PlacesAudio-lr1e-4-B128-S2Ms1571-SdT128-epoch20_val_200.mp4\n",
      "Success! Video file created: 103020 bytes\n",
      "Proceed to make the inference\n",
      "The model is in local\n",
      "-Model Loaded\n",
      "Sample already downloaded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/albert/UPF/SSL-TIE_TFG/utils/util.py:772: FutureWarning: Pass sr=16000, n_fft=400 as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel_basis = librosa.filters.mel(sr, n_fft, n_mels=num_mel_bins, fmin=fmin)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video created at: dir_exp_PlacesAudio/inferences/200/mm_SSL_TIE_PlacesAudio-lr1e-4-B128-S2Ms1571-SdT128-epoch40_val_200.mp4\n",
      "Success! Video file created: 104489 bytes\n",
      "Proceed to make the inference\n",
      "The model is in local\n",
      "-Model Loaded\n",
      "Sample already downloaded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/albert/UPF/SSL-TIE_TFG/utils/util.py:772: FutureWarning: Pass sr=16000, n_fft=400 as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel_basis = librosa.filters.mel(sr, n_fft, n_mels=num_mel_bins, fmin=fmin)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video created at: dir_exp_PlacesAudio/inferences/200/mm_SSL_TIE_PlacesAudio-lr1e-4-B128-S2Ms1571-SdT128-epoch51_val_200.mp4\n",
      "Success! Video file created: 117598 bytes\n"
     ]
    }
   ],
   "source": [
    "from utils.util import inference_maker\n",
    "import os\n",
    "\n",
    "local_dir_saving = \"dir_exp_PlacesAudio\"\n",
    "split = \"val\"\n",
    "samples_idx= [10,14,20,26,200]\n",
    "models = [\n",
    "    # {\"model_name\": \"SSL_TIE_PlacesAudio-lr1e-5-2ly-B128-SISA-1GPUS-wV\", \"epoch\": 13},\n",
    "    # {\"model_name\": \"SSL_TIE_PlacesAudio_lr1e-5-2ly-B32-MISA\", \"epoch\": 100},\n",
    "    # {\"model_name\": \"SSL_TIE_PlacesAudio_lr1e-5-2ly-B128-MISA\", \"epoch\": 100},\n",
    "    # {\"model_name\": \"SSL_TIE_PlacesAudio_lr1e-5-2ly-B256-MISA\", \"epoch\": 100},\n",
    "    # {\"model_name\": \"SSL_TIE_PlacesAudio_lr1e-5-2ly-B128-SISA\", \"epoch\": 100},\n",
    "    # {\"model_name\": \"SSL_TIE_PlacesAudio_lr1e-3-2ly-B128-SISA\", \"epoch\": 39},\n",
    "    # {\"model_name\": \"SSL_TIE_PlacesAudio_lr1e-4-2ly-B32-MISA\", \"epoch\": 100},\n",
    "    {\"model_name\": \"SSL_TIE_PlacesAudio-lr1e-4-B128-SISA-SdT128\",\"epoch\": 33},\n",
    "    {\"model_name\": \"SSL_TIE_PlacesAudio-lr1e-4-B128-SISA-SdT128\",\"epoch\": 20},\n",
    "    {\"model_name\": \"SSL_TIE_PlacesAudio-lr1e-4-B128-S2Ms1571-SdT128\", \"epoch\": 20},\n",
    "    {\"model_name\": \"SSL_TIE_PlacesAudio-lr1e-4-B128-S2Ms1571-SdT128\", \"epoch\": 40},\n",
    "    {\"model_name\": \"SSL_TIE_PlacesAudio-lr1e-4-B128-S2Ms1571-SdT128\", \"epoch\": 51}\n",
    "    \n",
    "]\n",
    "\n",
    "for sample_idx in samples_idx:\n",
    "    for model in models:\n",
    "        model_weights_path = os.path.join(local_dir_saving, f'{model[\"model_name\"]}-epoch{model[\"epoch\"]}.pth.tar')\n",
    "        remote_path = f'/home/asantos/models/to_test/{model[\"model_name\"]}-epoch{model[\"epoch\"]}.pth.tar'\n",
    "        \n",
    "        # upload_file_to_cluster(local_path=model_weights_path, remote_path=remote_path)\n",
    "\n",
    "        inference_maker(\n",
    "            model_name=model[\"model_name\"],\n",
    "            epoch=model[\"epoch\"],\n",
    "            split=split,\n",
    "            sample_idx=sample_idx,\n",
    "            local_dir_saving=local_dir_saving\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# All the code behind"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9.2\n"
     ]
    }
   ],
   "source": [
    "import librosa\n",
    "print(librosa.__version__)\n",
    "\n",
    "# import importlib.metadata\n",
    "\n",
    "# librosa_version = importlib.metadata.version(\"librosa\")\n",
    "# print(librosa_version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import scipy\n",
    "from torchvision import transforms\n",
    "import subprocess\n",
    "import json\n",
    "import os\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torchaudio\n",
    "import torchaudio.transforms as audio_T\n",
    "from models.model import AVENet\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "class GetSampleFromJson:\n",
    "    def __init__(self, json_file, local_dir):\n",
    "        self.json_file = json_file\n",
    "        self.local_dir = local_dir\n",
    "        with open(json_file, 'r') as f:\n",
    "            data_json = json.load(f)\n",
    "        self.data = data_json['data']\n",
    "        self.image_base_path = data_json['image_base_path']\n",
    "        self.audio_base_path = data_json['audio_base_path']\n",
    "        self._init_transforms()\n",
    "        self.AmplitudeToDB = audio_T.AmplitudeToDB()\n",
    "        self.audio_conf = {}\n",
    "        self.windows = {'hamming': scipy.signal.hamming,\n",
    "        'hann': scipy.signal.hann, 'blackman': scipy.signal.blackman,\n",
    "           'bartlett': scipy.signal.bartlett}\n",
    "    \n",
    "    def _init_transforms(self):\n",
    "        mean = [0.485, 0.456, 0.406]\n",
    "        std = [0.229, 0.224, 0.225]\n",
    "        self.img_transform = transforms.Compose([\n",
    "            transforms.Resize(224,Image.BICUBIC),\n",
    "            transforms.CenterCrop(224),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=mean, std=std)\n",
    "        ])\n",
    "\n",
    "    def get_sample(self, index):\n",
    "        sample = self.data[index]\n",
    "        image = os.path.join(self.image_base_path, sample['image'])\n",
    "        audio = os.path.join(self.audio_base_path, sample['wav'])\n",
    "        return image, audio\n",
    "    \n",
    "    def check_sample_in_local(self, index):\n",
    "        img, aud = self.get_sample(index)\n",
    "        img_local = os.path.join(self.local_dir + \"/frame\", img.split('/')[-1])\n",
    "        aud_local = os.path.join(self.local_dir + \"/audio\", aud.split('/')[-1])\n",
    "        return os.path.exists(img_local), os.path.exists(aud_local)\n",
    "    \n",
    "    def download_sample(self, index):\n",
    "\n",
    "        img_rem_path, aud_rem_path = self.get_sample(index)\n",
    "        if all(self.check_sample_in_local(index)):\n",
    "            print(\"Sample already downloaded\")\n",
    "        else:\n",
    "            print(f\"Sample NOT in {self.local_dir} \\n-> download  \")\n",
    "            command = [\"scp\", \"-P\", \"2122\", \"asantos@pirineus3.csuc.cat:\" + img_rem_path, self.local_dir+\"/frame\"]\n",
    "            print(command)\n",
    "            subprocess.run(command)\n",
    "            command = [\"scp\", \"-P\", \"2122\", \"asantos@pirineus3.csuc.cat:\" + aud_rem_path, self.local_dir+\"/audio\"]\n",
    "            print(command)\n",
    "            subprocess.run(command)\n",
    "            \n",
    "        img_local_path = os.path.join(self.local_dir+\"/frame\", img_rem_path.split('/')[-1])\n",
    "        aud_local_path = os.path.join(self.local_dir+\"/audio\", aud_rem_path.split('/')[-1])\n",
    "\n",
    "        return img_local_path, aud_local_path\n",
    "   \n",
    "    def load_image(self, image_path):\n",
    "        img = Image.open(image_path).convert('RGB')\n",
    "        img = self.img_transform(img)\n",
    "        return img\n",
    "    \n",
    "    def show_image(self, img_path):\n",
    "        img = cv2.imread(img_path)\n",
    "        cv2.imshow(\"image\", img)\n",
    "        cv2.waitKey(0)\n",
    "        cv2.destroyAllWindows()\n",
    "\n",
    "    def load_audio_to_spec(self, audio_path, processing_type=\"DAVENet\"):\n",
    "        if processing_type == \"DAVENet\":\n",
    "            audio = self.load_audio_DAVENet(audio_path)\n",
    "        elif processing_type == \"SSL-TIE\":\n",
    "            audio = self.load_audio_SSLTIE(audio_path)\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown processing type: {processing_type}\")\n",
    "        return audio\n",
    "    \n",
    "    def load_audio_SSLTIE(self, audio_path):\n",
    "        samples, samplerate = torchaudio.load(audio_path)\n",
    "\n",
    "        if samples.shape[1] < samplerate * 10:\n",
    "            n = int(samplerate * 10 / samples.shape[1]) + 1\n",
    "            samples = samples.repeat(1, n)\n",
    "\n",
    "        samples = samples[...,:samplerate*10]\n",
    "\n",
    "        spectrogram  =  audio_T.MelSpectrogram(\n",
    "                sample_rate=samplerate,\n",
    "                n_fft=512,\n",
    "                hop_length=239, \n",
    "                n_mels=257,\n",
    "                normalized=True\n",
    "            )(samples)\n",
    "        spectrogram =  self.AmplitudeToDB(spectrogram)\n",
    "        return spectrogram\n",
    "    \n",
    "    def preemphasis(self,signal,coeff=0.97):\n",
    "        \"\"\"perform preemphasis on the input signal.\n",
    "        \n",
    "        :param signal: The signal to filter.\n",
    "        :param coeff: The preemphasis coefficient. 0 is none, default 0.97.\n",
    "        :returns: the filtered signal.\n",
    "        \"\"\"    \n",
    "        return np.append(signal[0],signal[1:]-coeff*signal[:-1])\n",
    "    \n",
    "    def load_audio_DAVENet(self, file):\n",
    "        audio_type = self.audio_conf.get('audio_type', 'melspectrogram')\n",
    "        if audio_type not in ['melspectrogram', 'spectrogram']:\n",
    "            raise ValueError('Invalid audio_type specified in audio_conf. Must be one of [melspectrogram, spectrogram]')\n",
    "        preemph_coef = self.audio_conf.get('preemph_coef', 0.97)\n",
    "        sample_rate = self.audio_conf.get('sample_rate', 16000)\n",
    "        window_size = self.audio_conf.get('window_size', 0.025)\n",
    "        window_stride = self.audio_conf.get('window_stride', 0.01)\n",
    "        window_type = self.audio_conf.get('window_type', 'hamming')\n",
    "        num_mel_bins = self.audio_conf.get('num_mel_bins', 40)\n",
    "        target_length = self.audio_conf.get('target_length', 2048)\n",
    "        use_raw_length = self.audio_conf.get('use_raw_length', False)\n",
    "        padval = self.audio_conf.get('padval', 0)\n",
    "        fmin = self.audio_conf.get('fmin', 20)\n",
    "        n_fft = self.audio_conf.get('n_fft', int(sample_rate * window_size))\n",
    "        win_length = int(sample_rate * window_size)\n",
    "        hop_length = int(sample_rate * window_stride)\n",
    "\n",
    "        # load audio, subtract DC, preemphasis\n",
    "        y, sr = librosa.load(file,sr=sample_rate)\n",
    "        \n",
    "        if y.size == 0:\n",
    "            y = np.zeros(200)\n",
    "        y = y - y.mean()\n",
    "        y = self.preemphasis(y, preemph_coef)\n",
    "        # compute mel spectrogram\n",
    "        stft = librosa.stft(y, n_fft=n_fft, hop_length=hop_length,\n",
    "            win_length=win_length,\n",
    "            window=self.windows.get(window_type, self.windows['hamming']))\n",
    "        spec = np.abs(stft)**2\n",
    "        if audio_type == 'melspectrogram':\n",
    "            mel_basis = librosa.filters.mel(sr, n_fft, n_mels=num_mel_bins, fmin=fmin)\n",
    "            melspec = np.dot(mel_basis, spec)\n",
    "            logspec = librosa.power_to_db(melspec, ref=np.max)\n",
    "        elif audio_type == 'spectrogram':\n",
    "            logspec = librosa.power_to_db(spec, ref=np.max)\n",
    "        n_frames = logspec.shape[1]\n",
    "        if use_raw_length:\n",
    "            target_length = n_frames\n",
    "        p = target_length - n_frames\n",
    "        if p > 0:\n",
    "            logspec = np.pad(logspec, ((0,0),(0,p)), 'constant',\n",
    "                constant_values=(padval,padval))\n",
    "        elif p < 0:\n",
    "            logspec = logspec[:,0:p]\n",
    "            n_frames = target_length\n",
    "        logspec = torch.FloatTensor(logspec)\n",
    "        # return logspec, n_frames\n",
    "        return logspec.unsqueeze(0)\n",
    "        \n",
    "    \n",
    "\n",
    "class MatchmapVideoGenerator:\n",
    "    def __init__(self,model, device, img, spec,args, matchmap = None):\n",
    "        self.model = model\n",
    "        self.device = device\n",
    "        self.spec = Variable(spec.unsqueeze(0)).to(device, non_blocking=True) if spec.dim() == 3 else Variable(spec).to(device, non_blocking=True)\n",
    "        self.image = Variable(img.unsqueeze(0)).to(device, non_blocking=True) if img.dim() == 3 else Variable(img).to(device, non_blocking=True)\n",
    "        self.args = args\n",
    "        self.matchmap = matchmap\n",
    "        self.video = None\n",
    "\n",
    "    def compute_matchmap(self):\n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            img_emb,aud_emb = self.model(self.image.float(), self.spec.float(), self.args)\n",
    "            img_emb = img_emb.squeeze(0)\n",
    "            aud_emb = aud_emb.squeeze(0)\n",
    "            self.matchmap = torch.einsum('ct, chw -> thw',aud_emb,img_emb)\n",
    "        return self.matchmap\n",
    "    \n",
    "    def normalize_img(self, value, vmax=None, vmin=None):\n",
    "        '''\n",
    "        Normalize heatmap\n",
    "        '''\n",
    "        vmin = value.min() if vmin is None else vmin\n",
    "        vmax = value.max() if vmax is None else vmax\n",
    "        if not (vmax - vmin) == 0:\n",
    "            value = (value - vmin) / (vmax - vmin)  # vmin..vmax\n",
    "        return value\n",
    "    \n",
    "    def get_frame_match(self, img_np, matchmap_np, frame_idx):\n",
    "        assert img_np.ndim == 3, \"img_np should be a 3D numpy array\"\n",
    "        assert matchmap_np.ndim == 3, \"matchmap_np should be a 3D numpy array\"\n",
    "\n",
    "        matchmap_i = matchmap_np[frame_idx]\n",
    "        matchmap_i = cv2.resize(matchmap_i, dsize=(224, 224), interpolation=cv2.INTER_LINEAR)\n",
    "        matchmap_i = self.normalize_img(matchmap_i)\n",
    "        matchmap_i_photo = (matchmap_i * 255).astype(np.uint8)\n",
    "        matchmap_i_photo = cv2.applyColorMap(matchmap_i_photo, cv2.COLORMAP_JET)\n",
    "        matchmap_i_photo = cv2.addWeighted(matchmap_i_photo, 0.5, img_np, 0.5, 0)\n",
    "        return matchmap_i_photo\n",
    "    \n",
    "    def create_video_f(self,img_np, matchmap_np, output_path=\"matchmap_video.mp4\", fps=1):\n",
    "        n_frames = matchmap_np.shape[0]\n",
    "        \n",
    "        # Make sure img_np is in uint8 format\n",
    "        if img_np.dtype != np.uint8:\n",
    "            img_np = (img_np * 255).astype(np.uint8)\n",
    "        \n",
    "        # Make sure img_np has correct dimensions (224, 224, 3)\n",
    "        if img_np.shape[:2] != (224, 224):\n",
    "            img_np = cv2.resize(img_np, (224, 224))\n",
    "        \n",
    "        # Use proper codec for compatibility\n",
    "        # For better compatibility, try 'avc1' or 'H264' instead of 'mp4v'\n",
    "        fourcc = cv2.VideoWriter_fourcc(*'avc1') \n",
    "        \n",
    "        # Alternative codec options if 'avc1' doesn't work:\n",
    "        # fourcc = cv2.VideoWriter_fourcc(*'H264')\n",
    "        # fourcc = cv2.VideoWriter_fourcc(*'XVID')  # More compatible but lower quality\n",
    "        \n",
    "        out = cv2.VideoWriter(output_path, fourcc, fps, (224, 224))\n",
    "        \n",
    "        if not out.isOpened():\n",
    "            print(\"Failed to create VideoWriter. Trying alternative codec...\")\n",
    "            # Try with different codec\n",
    "            fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "            out = cv2.VideoWriter(output_path.replace('.mp4', '.avi'), fourcc, fps, (224, 224))\n",
    "        \n",
    "        for i in range(n_frames):\n",
    "            frame = self.get_frame_match(img_np, matchmap_np, i)\n",
    "            \n",
    "            # Ensure frame is the correct format\n",
    "            if frame.dtype != np.uint8:\n",
    "                frame = (frame * 255).astype(np.uint8)\n",
    "                \n",
    "            # Ensure frame has the right shape\n",
    "            if frame.shape[:2] != (224, 224):\n",
    "                frame = cv2.resize(frame, (224, 224))\n",
    "                \n",
    "            # Verify frame is BGR (OpenCV's default format)\n",
    "            if len(frame.shape) == 3 and frame.shape[2] == 3:\n",
    "                out.write(frame)\n",
    "            else:\n",
    "                print(f\"Warning: Frame {i} has incorrect format. Shape: {frame.shape}\")\n",
    "        \n",
    "        out.release()\n",
    "        print(f\"Video created at: {output_path}\")\n",
    "        \n",
    "        # Verify the file was created and has a non-zero size\n",
    "        if os.path.exists(output_path) and os.path.getsize(output_path) > 0:\n",
    "            print(f\"Success! Video file created: {os.path.getsize(output_path)} bytes\")\n",
    "        else:\n",
    "            print(\"Error: Video file was not created properly\")\n",
    "            \n",
    "\n",
    "    def create_video(self,output_path):\n",
    "        img_np = self.image[0].cpu().numpy()\n",
    "        img_np = np.transpose(img_np, (1, 2, 0))\n",
    "        img_np = self.normalize_img(img_np)\n",
    "        img_np = (img_np * 255).astype(np.uint8)\n",
    "        img_np = cv2.cvtColor(img_np, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "        if self.matchmap is None:\n",
    "            self.matchmap = self.compute_matchmap()\n",
    "\n",
    "        matchmap_np = self.matchmap.cpu().numpy()\n",
    "        n_frames = matchmap_np.shape[0]\n",
    "        self.create_video_f(img_np, matchmap_np, output_path, fps=n_frames/10) # 10 sec duration\n",
    "\n",
    "\n",
    "    def add_audio_to_video(self, video_path, audio_path,verbose=False):\n",
    "        \"\"\"\n",
    "        Add audio to video using ffmpeg and overwrite the output file if it exists.\n",
    "        \"\"\"\n",
    "        temp_output = \"temp_output.mp4\"\n",
    "        \n",
    "        # Ensure the audio file exists\n",
    "        if not os.path.exists(audio_path):\n",
    "            raise Exception(\"Error: Audio file not found.\")\n",
    "\n",
    "        # Use ffmpeg to merge audio and video\n",
    "        command = [\n",
    "            \"ffmpeg\",\n",
    "            \"-y\",  # Overwrite output files without asking\n",
    "            \"-i\", video_path,  # Input video\n",
    "            # \"-stream_loop\", \"-1\",  # Infinite loop for audio\n",
    "            \"-i\", audio_path,  # Input audio\n",
    "            \"-map\", \"0:v\",  # Video stream from first input\n",
    "            \"-map\", \"1:a\",  # Audio stream from second input\n",
    "            \"-c:v\", \"copy\",  # Copy video codec (no re-encoding)\n",
    "            \"-c:a\", \"libmp3lame\",  # Encode audio in mp3 format\n",
    "            \"-t\", \"10\",  # 10 sec duration\n",
    "            temp_output\n",
    "        ]\n",
    "        \n",
    "        \n",
    "        try:\n",
    "            if verbose:\n",
    "                # Suppress ffmpeg output\n",
    "                with open(os.devnull, 'w') as devnull:\n",
    "                    subprocess.run(command, stdout=devnull, stderr=devnull, check=True)\n",
    "            else:   \n",
    "                subprocess.run(command, check=True)\n",
    "            # Delete the original video file\n",
    "            os.remove(video_path)\n",
    "            # Rename the temporary output file to the original video file\n",
    "            os.rename(temp_output, video_path)\n",
    "        except subprocess.CalledProcessError:\n",
    "            print(\"Error adding audio to video.\")\n",
    "\n",
    "\n",
    "    def create_video_with_audio(self, output_path, audio_path):\n",
    "        self.create_video(output_path)\n",
    "        self.add_audio_to_video(output_path, audio_path)\n",
    "\n",
    "def load_model(ckpt_path, args):\n",
    "    model = AVENet(args)\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    checkpoint = torch.load(ckpt_path, map_location=device)\n",
    "    model.load_state_dict(checkpoint['state_dict'])\n",
    "    model.to(device)\n",
    "    return model, device\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_39074/811875018.py:35: DeprecationWarning: BICUBIC is deprecated and will be removed in Pillow 10 (2023-07-01). Use Resampling.BICUBIC instead.\n",
      "  transforms.Resize(224,Image.BICUBIC),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample already downloaded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_39074/811875018.py:151: FutureWarning: Pass sr=16000, n_fft=400 as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel_basis = librosa.filters.mel(sr, n_fft, n_mels=num_mel_bins, fmin=fmin)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from opts import get_arguments\n",
    "\n",
    "# Simulate command-line arguments\n",
    "sys.argv = ['script_name', '--order_3_tensor', '--simtype', 'MISA']\n",
    "\n",
    "args = get_arguments()\n",
    "\n",
    "#JSON\n",
    "split = \"val\"\n",
    "json_file = f\"garbage/{split}.json\"\n",
    "local_dir_saving = \"dir_exp_PlacesAudio\"\n",
    "\n",
    "# Load model\n",
    "# model_name = \"2layers_lr1e-5_epoch100\"\n",
    "# model_name = \"2layers_lr1e-5_epoch1\"\n",
    "# model_name = \"lr1e-5_2layersB256_epoch100\"\n",
    "\n",
    "# checkpoint_path = f'garbage/{model_name}.pth.tar'\n",
    "# model,device = load_model(checkpoint_path, args)\n",
    "\n",
    "#SAMPLE\n",
    "sample_idx = 9\n",
    "\n",
    "# Get the image and audio\n",
    "gs = GetSampleFromJson(json_file,local_dir_saving)\n",
    "img_local_path, aud_local_path = gs.download_sample(sample_idx)\n",
    "\n",
    "img = gs.load_image(img_local_path)\n",
    "spec = gs.load_audio_to_spec(aud_local_path)\n",
    "\n",
    "# # Generate the video\n",
    "# mgv = MatchmapVideoGenerator(model,device,img,spec,args)\n",
    "# # mgv.create_video(local_dir_saving+ f\"/mm_{model_name}_{split}_{sample_idx}.mp4\")\n",
    "# mgv.create_video_with_audio(local_dir_saving+ f\"/mm_{model_name}_{split}_{sample_idx}.mp4\", aud_local_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Class for everything\n",
    "This class will be able to process the txt file of the desired model, and download the model with the desired weights and maybe retrieve the video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "links_SSL_TIE_PlacesAudio-lr1e-5-2ly-B128-SISA-1GPUS-wV_135932.json\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "def folder_exists_in_cluster(remote_path):\n",
    "    # Command to check if the folder exists\n",
    "    check_command = f\"ssh -p 2122 asantos@pirineus3.csuc.cat '[ -d \\\"{remote_path}\\\" ] && echo Exists || echo NotExists'\"\n",
    "    result = subprocess.run(check_command, shell=True, capture_output=True, text=True)\n",
    "    \n",
    "    return result.stdout.strip() == \"Exists\"\n",
    "\n",
    "def count_files_in_folder(remote_path):\n",
    "    # Command to count files in the folder\n",
    "    count_command = f\"ssh -p 2122 asantos@pirineus3.csuc.cat 'ls -1 \\\"{remote_path}\\\" | wc -l'\"\n",
    "    result = subprocess.run(count_command, shell=True, capture_output=True, text=True)\n",
    "\n",
    "    return int(result.stdout.strip()) if result.stdout.strip().isdigit() else 0\n",
    "\n",
    "def list_files_in_remote_folder(remote_path):\n",
    "    # Command to list all files in the remote folder\n",
    "    list_command = f\"ssh -p 2122 asantos@pirineus3.csuc.cat 'ls -1 \\\"{remote_path}\\\"'\"\n",
    "    result = subprocess.run(list_command, shell=True, capture_output=True, text=True)\n",
    "    \n",
    "    if result.returncode == 0:\n",
    "        return result.stdout.strip().split('\\n') if result.stdout.strip() else []\n",
    "    else:\n",
    "        print(f\"Error listing files in remote folder: {result.stderr}\")\n",
    "        return []\n",
    "\n",
    "def download_remote_file(remote_path, local_path):\n",
    "    \"\"\"\n",
    "    Downloads a specific file from a remote folder to a local folder using scp.\n",
    "    \"\"\"\n",
    "    # Check if the file already exists locally\n",
    "    if os.path.exists(local_path):\n",
    "        print(f\"File already exists locally: {local_path}\")\n",
    "        return\n",
    "\n",
    "    # Ensure the local directory exists\n",
    "    local_dir = os.path.dirname(local_path)\n",
    "    if not os.path.exists(local_dir):\n",
    "        os.makedirs(local_dir) \n",
    "    \n",
    "\n",
    "    # Command to download the specific file\n",
    "    download_command = f\"scp -P 2122 asantos@pirineus3.csuc.cat:\\\"{remote_path}\\\" \\\"{local_path}\\\"\"\n",
    "    result = subprocess.run(download_command, shell=True, capture_output=True, text=True)\n",
    "\n",
    "    if result.returncode == 0:\n",
    "        print(f\"Successfully downloaded {remote_path} to {local_path}\")\n",
    "    else:\n",
    "        print(f\"Error downloading {remote_path}: {result.stderr}\")\n",
    "\n",
    "\n",
    "def upload_file_to_cluster(local_path, remote_path):\n",
    "    \"\"\"\n",
    "    Uploads a specific file from a local folder to a remote folder using scp.\n",
    "    \"\"\"\n",
    "    # Check if the local file exists\n",
    "    if not os.path.exists(local_path):\n",
    "        print(f\"Local file does not exist: {local_path}\")\n",
    "        return\n",
    "\n",
    "    # Ensure the remote directory exists\n",
    "    remote_dir = os.path.dirname(remote_path)\n",
    "    create_remote_dir_command = f\"ssh -p 2122 asantos@pirineus3.csuc.cat 'mkdir -p \\\"{remote_dir}\\\"'\"\n",
    "    subprocess.run(create_remote_dir_command, shell=True, capture_output=True, text=True)\n",
    "\n",
    "    # Command to upload the specific file\n",
    "    upload_command = f\"scp -P 2122 \\\"{local_path}\\\" asantos@pirineus3.csuc.cat:\\\"{remote_path}\\\"\"\n",
    "    result = subprocess.run(upload_command, shell=True, capture_output=True, text=True)\n",
    "\n",
    "    if result.returncode == 0:\n",
    "        print(f\"Successfully uploaded {local_path} to {remote_path}\")\n",
    "    else:\n",
    "        print(f\"Error uploading {local_path}: {result.stderr}\")\n",
    "# print(folder_exists_in_cluster(remote_path=\"code\"))\n",
    "# print(count_files_in_folder(remote_path=\"code\"), type(count_files_in_folder(remote_path=\"code\")))\n",
    "print((list_files_in_remote_folder(\"models/SSL_TIE_PlacesAudio-lr1e-5-2ly-B128-SISA-1GPUS-wV\")[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_name = \"try_json\"\n",
    "folder_exists_in_cluster(f'models/{model_name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using links_SSL_TIE_PlacesAudio-lr1e-5-2ly-B128-SISA-1GPUS-wV_135932.json\n",
      "The model is no longer available.\n",
      "91\n",
      "{'time_creation': '2025-03-25 18:32', 'learning_rate': 1e-05, 'batch_size': 128, 'simtype': 'SISA', 'temperature': 0.07, 'val_video_idx': 10}\n",
      "/scratch/upftfg03/asantos/135932/SSL_TIE_PlacesAudio-lr1e-5-2ly-B128-SISA-1GPUS-wV/model/epoch1.pth.tar\n",
      "Downloading video\n",
      "Error downloading /scratch/upftfg03/asantos/135932/SSL_TIE_PlacesAudio-lr1e-5-2ly-B128-SISA-1GPUS-wV/img/val_videos/epoch_59.mp4: scp: /scratch/upftfg03/asantos/135932/SSL_TIE_PlacesAudio-lr1e-5-2ly-B128-SISA-1GPUS-wV/img/val_videos/epoch_59.mp4: No such file or directory\n",
      "\n",
      "garbage/mm_SSL_TIE_PlacesAudio-lr1e-5-2ly-B128-SISA-1GPUS-wV-epoch59_val_10.mp4\n",
      "Downloading weigths\n",
      "Error downloading /scratch/upftfg03/asantos/135932/SSL_TIE_PlacesAudio-lr1e-5-2ly-B128-SISA-1GPUS-wV/model/epoch59.pth.tar: scp: /scratch/upftfg03/asantos/135932/SSL_TIE_PlacesAudio-lr1e-5-2ly-B128-SISA-1GPUS-wV/model/epoch59.pth.tar: No such file or directory\n",
      "\n",
      "garbage/SSL_TIE_PlacesAudio-lr1e-5-2ly-B128-SISA-1GPUS-wV-epoch59.pth.tar\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime, timedelta\n",
    "import os\n",
    "import json\n",
    "import subprocess\n",
    "import numpy as np\n",
    "import cv2\n",
    "import torch\n",
    "class ModelOutputRetriever:\n",
    "    def __init__(self,model_name,local_dir):\n",
    "        self.model_name = model_name\n",
    "        self.model_dir = os.path.join(\"models\",model_name)\n",
    "        self.local_dir = local_dir\n",
    "        #Check if the folder exists\n",
    "        if not folder_exists_in_cluster(self.model_dir):\n",
    "            raise Exception(f\"Model {model_name} doesn't exist among models\")\n",
    "        \n",
    "        # - if more than one ask the user which one if not use that one\n",
    "        filenames = list_files_in_remote_folder(self.model_dir)\n",
    "        if len(filenames) > 1:\n",
    "            request_string = f\"There's more than one json for {model_name}\\nChoose one:\\n\"\n",
    "            for idx, flname in enumerate(filenames):\n",
    "                file_string = f\"[{str(idx)}] {flname}\\n\"\n",
    "                request_string = request_string + file_string\n",
    "            idx_to_process = int(input(request_string))\n",
    "\n",
    "            print(f\"Using [{str(idx_to_process)}] {filenames[idx_to_process]}\")\n",
    "\n",
    "        else:\n",
    "            idx_to_process = 0\n",
    "            print(f\"Using {filenames[0]}\")\n",
    "        \n",
    "        #check if json is in local if not download\n",
    "        json_file = filenames[idx_to_process]\n",
    "        if not self.check_in_local(json_file):\n",
    "            download_remote_file(\n",
    "                remote_path = os.path.join(self.model_dir,json_file),\n",
    "                local_path = os.path.join(self.local_dir,json_file)\n",
    "                ) \n",
    "        self.json_file = os.path.join(self.local_dir,json_file)\n",
    "        \n",
    "        with open(self.json_file, 'r') as f:\n",
    "            self.data_json = json.load(f)\n",
    "\n",
    "        self.check_if_available()\n",
    "        \n",
    "\n",
    "    def check_in_local(self,file):\n",
    "        return os.path.exists(os.path.join(self.local_dir,file))\n",
    "            \n",
    "\n",
    "    def get_number_of_epochs(self):\n",
    "        return len(self.data_json) - 1\n",
    "    \n",
    "    def get_parameters(self):\n",
    "        return self.data_json['parameters']\n",
    "    \n",
    "    def get_weigths_link(self, epoch):\n",
    "        return self.data_json[str(epoch)]['weights_link']\n",
    "    \n",
    "    def download_weigths(self, epoch):\n",
    "        weigths_link = self.get_weigths_link(epoch)\n",
    "        weigths_name = self.model_name + \"-\" + weigths_link.split('/')[-1]\n",
    "        if not self.check_in_local(weigths_name):\n",
    "            print(\"Downloading weigths\")\n",
    "            download_remote_file(\n",
    "                remote_path = weigths_link,\n",
    "                local_path = os.path.join(self.local_dir,weigths_name)\n",
    "            )\n",
    "        else:\n",
    "            print(\"Weights already in local dir\")\n",
    "        return os.path.join(self.local_dir,weigths_name)\n",
    "    \n",
    "    def get_video_link(self, epoch):\n",
    "        return self.data_json[str(epoch)]['video_link']\n",
    "    \n",
    "    def download_video(self, epoch, path_2_save = None):\n",
    "        video_link = self.get_video_link(epoch)\n",
    "        sample_idx = self.data_json[\"parameters\"][\"val_video_idx\"]\n",
    "        video_name = f'mm_{self.model_name}-epoch{epoch}_val_{sample_idx}.mp4'\n",
    "        if not self.check_in_local(video_name):\n",
    "            print(\"Downloading video\")\n",
    "            download_remote_file(\n",
    "                remote_path = video_link,\n",
    "                local_path = os.path.join(path_2_save if path_2_save else self.local_dir\n",
    "                                          ,video_name)\n",
    "            )\n",
    "        else:\n",
    "            print(\"Video already in local dir\")\n",
    "        return os.path.join(self.local_dir,video_name)\n",
    "    \n",
    "    def check_if_available(self):\n",
    "        \"\"\"\n",
    "        Check if 7 seven days have passed since the time creation\n",
    "        \"\"\"\n",
    "        # Parse the time_creation string into a datetime object\n",
    "        creation_time = datetime.strptime(self.data_json[\"parameters\"][\"time_creation\"], \"%Y-%m-%d %H:%M\")\n",
    "\n",
    "        # Check if 7 days have passed since the creation time\n",
    "        if datetime.now() - creation_time > timedelta(days=7):\n",
    "            print(\"The model is no longer available.\")\n",
    "            return False\n",
    "        else:\n",
    "            print(\"The model is still available. Creation time: \",creation_time)\n",
    "            time_difference = timedelta(days=7) - (datetime.now() - creation_time)\n",
    "            days = time_difference.days\n",
    "            hours = time_difference.seconds // 3600\n",
    "\n",
    "            if days > 0:\n",
    "                print(f\"The model will be available for {days} more days.\")\n",
    "            else:\n",
    "                print(f\"The model will be available for {hours} more hours.\")\n",
    "            return True\n",
    "    \n",
    "      \n",
    "model_name = \"SSL_TIE_PlacesAudio-lr1e-5-2ly-B128-SISA-1GPUS-wV\"\n",
    "local_dir_saving = \"garbage\"\n",
    "mor = ModelOutputRetriever(model_name,local_dir_saving)\n",
    "print(mor.get_number_of_epochs())\n",
    "print(mor.get_parameters())\n",
    "print(mor.get_weigths_link(1))\n",
    "print(mor.download_video(59,\"dir_exp_PlacesAudio\"))\n",
    "print(mor.download_weigths(59))\n",
    "\n",
    "        \n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "invalid literal for int() with base 10: ''",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m model_name2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtry_json\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 2\u001b[0m mor2\u001b[38;5;241m=\u001b[39m \u001b[43mModelOutputRetriever\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_name2\u001b[49m\u001b[43m,\u001b[49m\u001b[43mlocal_dir_saving\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[5], line 24\u001b[0m, in \u001b[0;36mModelOutputRetriever.__init__\u001b[0;34m(self, model_name, local_dir)\u001b[0m\n\u001b[1;32m     22\u001b[0m         file_string \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(idx)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mflname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     23\u001b[0m         request_string \u001b[38;5;241m=\u001b[39m request_string \u001b[38;5;241m+\u001b[39m file_string\n\u001b[0;32m---> 24\u001b[0m     idx_to_process \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mrequest_string\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUsing [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(idx_to_process)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfilenames[idx_to_process]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mValueError\u001b[0m: invalid literal for int() with base 10: ''"
     ]
    }
   ],
   "source": [
    "model_name2 = \"try_json\"\n",
    "mor2= ModelOutputRetriever(model_name2,local_dir_saving)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Mega Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from opts import get_arguments\n",
    "\n",
    "\n",
    "def inference_maker(model_name, epoch, split, sample_idx, local_dir_saving):\n",
    "    inference_name = f'mm_{model_name}-epoch{epoch}_{split}_{sample_idx}.mp4'\n",
    "    inference_local_path = os.path.join(local_dir_saving, \"inferences\", str(sample_idx), inference_name)\n",
    "\n",
    "    if os.path.exists(inference_local_path):\n",
    "        print(\"Inference already in local\")\n",
    "        return inference_local_path\n",
    "    print(\"Proceed to make the inference\")\n",
    "\n",
    "    # Ensure the directory for inference_local_path exists\n",
    "    inference_dir = os.path.dirname(inference_local_path)\n",
    "    if not os.path.exists(inference_dir):\n",
    "        os.makedirs(inference_dir)\n",
    "\n",
    "    model_weights_path = os.path.join(local_dir_saving,\n",
    "                                      f'{model_name}-epoch{epoch}.pth.tar')\n",
    "    \n",
    "    # Simulate command-line arguments for loading the model\n",
    "    sys.argv = ['script_name', '--order_3_tensor', '--simtype', 'MISA']\n",
    "\n",
    "    args = get_arguments()\n",
    "\n",
    "    #Check if the model exist in local\n",
    "    if os.path.exists(model_weights_path):\n",
    "        print(\"The model is in local\")\n",
    "        model, device = load_model(model_weights_path,args)\n",
    "        print(\"-Model Loaded\")\n",
    "    else:\n",
    "        #Request if user wants to download the model\n",
    "        user_input = input(\"Model weights not found locally. Do you want to download them? (yes/no): \").strip().lower()\n",
    "        if user_input == \"yes\":\n",
    "            mor = ModelOutputRetriever(model_name, local_dir_saving)\n",
    "            model_weights_path = mor.download_weigths(epoch)\n",
    "            model, device = load_model(model_weights_path, args)\n",
    "            print(\"-Model Loaded\")\n",
    "        else:\n",
    "            raise FileNotFoundError(\"Model weights are required but not available locally.\")\n",
    "    \n",
    "    #Check if the audio and the image of the sample index is in local\n",
    "    json_file = f'garbage/{split}.json'\n",
    "    if os.path.exists(json_file):\n",
    "        gs = GetSampleFromJson(json_file, local_dir_saving)\n",
    "        img_local_path, aud_local_path = gs.download_sample(sample_idx)\n",
    "    else:\n",
    "        raise FileNotFoundError(\"json file not found for retrieving the samples\")\n",
    "\n",
    "    img = gs.load_image(img_local_path)\n",
    "    spec = gs.load_audio_to_spec(aud_local_path)\n",
    "\n",
    "    mgv = MatchmapVideoGenerator(model, device, img, spec, args)\n",
    "    mgv.create_video_with_audio(inference_local_path, aud_local_path)\n",
    "    \n",
    "    \n",
    "    return inference_local_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proceed to make the inference\n",
      "The model is in local\n",
      "-Model Loaded\n",
      "Sample NOT in dir_exp_PlacesAudio \n",
      "-> download  \n",
      "['scp', '-P', '2122', 'asantos@pirineus3.csuc.cat:/data/upftfg03/asantos/PlacesAudio_400k_distro/images256/p/picnic_area/gsun_0782ffe2a06a466eb3b1d44049b92c89.jpg', 'dir_exp_PlacesAudio/frame']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1355/1936299536.py:29: DeprecationWarning: BICUBIC is deprecated and will be removed in Pillow 10 (2023-07-01). Use Resampling.BICUBIC instead.\n",
      "  transforms.Resize(224,Image.BICUBIC),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['scp', '-P', '2122', 'asantos@pirineus3.csuc.cat:/data/upftfg03/asantos/PlacesAudio_400k_distro/wavs/3/utterance_35672.wav', 'dir_exp_PlacesAudio/audio']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/albert/miniconda3/envs/ssl-cpu/lib/python3.8/site-packages/torchaudio/functional/functional.py:576: UserWarning: At least one mel filterbank has all zero values. The value for `n_mels` (257) may be set too high. Or, the value for `n_freqs` (257) may be set too low.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video created at: dir_exp_PlacesAudio/mm_SSL_TIE_PlacesAudio-lr1e-5-2ly-B128-SISA-1GPUS-wV-epoch50_val_17.mp4\n",
      "Success! Video file created: 172201 bytes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ffmpeg version 5.1.2 Copyright (c) 2000-2022 the FFmpeg developers\n",
      "  built with gcc 11.3.0 (conda-forge gcc 11.3.0-19)\n",
      "  configuration: --prefix=/home/albert/miniconda3/envs/ssl-cpu --cc=/home/conda/feedstock_root/build_artifacts/ffmpeg_1674566204550/_build_env/bin/x86_64-conda-linux-gnu-cc --cxx=/home/conda/feedstock_root/build_artifacts/ffmpeg_1674566204550/_build_env/bin/x86_64-conda-linux-gnu-c++ --nm=/home/conda/feedstock_root/build_artifacts/ffmpeg_1674566204550/_build_env/bin/x86_64-conda-linux-gnu-nm --ar=/home/conda/feedstock_root/build_artifacts/ffmpeg_1674566204550/_build_env/bin/x86_64-conda-linux-gnu-ar --disable-doc --disable-openssl --enable-demuxer=dash --enable-hardcoded-tables --enable-libfreetype --enable-libfontconfig --enable-libopenh264 --enable-gnutls --enable-libmp3lame --enable-libvpx --enable-pthreads --enable-vaapi --enable-gpl --enable-libx264 --enable-libx265 --enable-libaom --enable-libsvtav1 --enable-libxml2 --enable-pic --enable-shared --disable-static --enable-version3 --enable-zlib --enable-libopus --pkg-config=/home/conda/feedstock_root/build_artifacts/ffmpeg_1674566204550/_build_env/bin/pkg-config\n",
      "  libavutil      57. 28.100 / 57. 28.100\n",
      "  libavcodec     59. 37.100 / 59. 37.100\n",
      "  libavformat    59. 27.100 / 59. 27.100\n",
      "  libavdevice    59.  7.100 / 59.  7.100\n",
      "  libavfilter     8. 44.100 /  8. 44.100\n",
      "  libswscale      6.  7.100 /  6.  7.100\n",
      "  libswresample   4.  7.100 /  4.  7.100\n",
      "  libpostproc    56.  6.100 / 56.  6.100\n",
      "Input #0, mov,mp4,m4a,3gp,3g2,mj2, from 'dir_exp_PlacesAudio/mm_SSL_TIE_PlacesAudio-lr1e-5-2ly-B128-SISA-1GPUS-wV-epoch50_val_17.mp4':\n",
      "  Metadata:\n",
      "    major_brand     : isom\n",
      "    minor_version   : 512\n",
      "    compatible_brands: isomiso2avc1mp41\n",
      "    encoder         : Lavf59.27.100\n",
      "  Duration: 00:00:10.00, start: 0.000000, bitrate: 137 kb/s\n",
      "  Stream #0:0[0x1](und): Video: h264 (High) (avc1 / 0x31637661), yuv420p(progressive), 224x224, 136 kb/s, 4.20 fps, 4.20 tbr, 10752 tbn (default)\n",
      "    Metadata:\n",
      "      handler_name    : VideoHandler\n",
      "      vendor_id       : [0][0][0][0]\n",
      "Guessed Channel Layout for Input Stream #1.0 : mono\n",
      "Input #1, wav, from 'dir_exp_PlacesAudio/audio/utterance_35672.wav':\n",
      "  Duration: 00:00:05.72, bitrate: 256 kb/s\n",
      "  Stream #1:0: Audio: pcm_s16le ([1][0][0][0] / 0x0001), 16000 Hz, mono, s16, 256 kb/s\n",
      "Stream mapping:\n",
      "  Stream #0:0 -> #0:0 (copy)\n",
      "  Stream #1:0 -> #0:1 (pcm_s16le (native) -> mp3 (libmp3lame))\n",
      "Press [q] to stop, [?] for help\n",
      "Output #0, mp4, to 'temp_output.mp4':\n",
      "  Metadata:\n",
      "    major_brand     : isom\n",
      "    minor_version   : 512\n",
      "    compatible_brands: isomiso2avc1mp41\n",
      "    encoder         : Lavf59.27.100\n",
      "  Stream #0:0(und): Video: h264 (High) (avc1 / 0x31637661), yuv420p(progressive), 224x224, q=2-31, 136 kb/s, 4.20 fps, 4.20 tbr, 10752 tbn (default)\n",
      "    Metadata:\n",
      "      handler_name    : VideoHandler\n",
      "      vendor_id       : [0][0][0][0]\n",
      "  Stream #0:1: Audio: mp3 (mp4a / 0x6134706D), 16000 Hz, mono, s16p\n",
      "    Metadata:\n",
      "      encoder         : Lavc59.37.100 libmp3lame\n",
      "frame=   42 fps=0.0 q=-1.0 Lsize=     199kB time=00:00:10.01 bitrate= 162.7kbits/s speed= 111x    \n",
      "video:167kB audio:30kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: 1.280113%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'dir_exp_PlacesAudio/mm_SSL_TIE_PlacesAudio-lr1e-5-2ly-B128-SISA-1GPUS-wV-epoch50_val_17.mp4'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_name = \"SSL_TIE_PlacesAudio-lr1e-5-2ly-B128-SISA-1GPUS-wV\"\n",
    "\n",
    "inference_maker(\n",
    "    model_name=model_name,\n",
    "    epoch=50,\n",
    "    split=\"val\",\n",
    "    sample_idx=17,\n",
    "    local_dir_saving=\"dir_exp_PlacesAudio\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already exists locally: dir_exp_PlacesAudio/SSL_TIE_PlacesAudio_lr1e-5-2ly-B32-MISA-epoch100.pth.tar\n"
     ]
    }
   ],
   "source": [
    "download_remote_file(\n",
    "    remote_path=\"/home/asantos/models/SSL_TIE_PlacesAudio_lr1e-5_2layers/model/epoch100.pth.tar\",\n",
    "    local_path=os.path.join(local_dir_saving,\"SSL_TIE_PlacesAudio_lr1e-5-2ly-B32-MISA-epoch100.pth.tar\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully downloaded /home/asantos/models/SSL_TIE_PlacesAudio_lr1e-5_2layersB256/model/epoch100.pth.tar to dir_exp_PlacesAudio/SSL_TIE_PlacesAudio_lr1e-5-2ly-B256-MISA-epoch100.pth.tar\n"
     ]
    }
   ],
   "source": [
    "download_remote_file(\n",
    "    remote_path=\"/home/asantos/models/SSL_TIE_PlacesAudio_lr1e-5_2layersB256/model/epoch100.pth.tar\",\n",
    "    local_path=os.path.join(local_dir_saving,\"SSL_TIE_PlacesAudio_lr1e-5-2ly-B256-MISA-epoch100.pth.tar\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully downloaded /home/asantos/models/SSL_TIE_PlacesAudio_lr1e-5_2layersB128/model/epoch100.pth.tar to dir_exp_PlacesAudio/SSL_TIE_PlacesAudio_lr1e-5-2ly-B128-MISA-epoch100.pth.tar\n"
     ]
    }
   ],
   "source": [
    "download_remote_file(\n",
    "    remote_path=\"/home/asantos/models/SSL_TIE_PlacesAudio_lr1e-5_2layersB128/model/epoch100.pth.tar\",\n",
    "    local_path=os.path.join(local_dir_saving,\"SSL_TIE_PlacesAudio_lr1e-5-2ly-B128-MISA-epoch100.pth.tar\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully downloaded /home/asantos/models/SSL_TIE_PlacesAudio-lr1e-3-2ly-B128-SISA/model/epoch39.pth.tar to dir_exp_PlacesAudio/SSL_TIE_PlacesAudio_lr1e-3-2ly-B128-SISA-epoch39.pth.tar\n"
     ]
    }
   ],
   "source": [
    "download_remote_file(\n",
    "    remote_path=\"/home/asantos/models/SSL_TIE_PlacesAudio-lr1e-3-2ly-B128-SISA/model/epoch39.pth.tar\",\n",
    "    local_path=os.path.join(local_dir_saving,\"SSL_TIE_PlacesAudio_lr1e-3-2ly-B128-SISA-epoch39.pth.tar\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully downloaded /home/asantos/models/SSL_TIE_PlacesAudio_lr1e-4_2layers/model/epoch100.pth.tar to dir_exp_PlacesAudio/SSL_TIE_PlacesAudio_lr1e-4-2ly-B32-MISA-epoch100.pth.tar\n"
     ]
    }
   ],
   "source": [
    "download_remote_file(\n",
    "    remote_path=\"/home/asantos/models/SSL_TIE_PlacesAudio_lr1e-4_2layers/model/epoch100.pth.tar\",\n",
    "    local_path=os.path.join(local_dir_saving,\"SSL_TIE_PlacesAudio_lr1e-4-2ly-B32-MISA-epoch100.pth.tar\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully downloaded /home/asantos/models/SSL_TIE_PlacesAudio-lr1e-5-2ly-B128-SISA/model/epoch100.pth.tar to dir_exp_PlacesAudio/SSL_TIE_PlacesAudio_lr1e-5-2ly-B128-SISA-epoch100.pth.tar\n"
     ]
    }
   ],
   "source": [
    "download_remote_file(\n",
    "    remote_path=\"/home/asantos/models/SSL_TIE_PlacesAudio-lr1e-5-2ly-B128-SISA/model/epoch100.pth.tar\",\n",
    "    local_path=os.path.join(local_dir_saving,\"SSL_TIE_PlacesAudio_lr1e-5-2ly-B128-SISA-epoch100.pth.tar\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already exists locally: dir_exp_PlacesAudio/SSL_TIE_PlacesAudio_lr1e-5-epoch100.pth.tar\n"
     ]
    }
   ],
   "source": [
    "local_dir_saving = \"dir_exp_PlacesAudio\"\n",
    "# Download\n",
    "download_remote_file(\n",
    "    remote_path=\"/home/asantos/models/SSL_TIE_PlacesAudio_lr1e-5/model/epoch100.pth.tar\",\n",
    "    local_path=os.path.join(local_dir_saving,\"SSL_TIE_PlacesAudio_lr1e-5-epoch100.pth.tar\")\n",
    ")\n",
    "# new_filename = \"SSL_TIE_PlacesAudio_lr1e-5-epoch100.pth.tar\"\n",
    "# os.rename(os.path.join(local_dir_saving, \"epoch100.pth.tar\"), os.path.join(local_dir_saving, new_filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample already downloaded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_39074/811875018.py:35: DeprecationWarning: BICUBIC is deprecated and will be removed in Pillow 10 (2023-07-01). Use Resampling.BICUBIC instead.\n",
      "  transforms.Resize(224,Image.BICUBIC),\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('dir_exp_PlacesAudio/frame/gsun_f24657c66201deb03ac489eb52f967f0.jpg',\n",
       " 'dir_exp_PlacesAudio/audio/utterance_183783.wav')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs1 = GetSampleFromJson(json_file,local_dir_saving)\n",
    "gs1.download_sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proceed to make the inference\n",
      "The model is in local\n",
      "-Model Loaded\n",
      "Sample already downloaded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1183/3025049354.py:35: DeprecationWarning: BICUBIC is deprecated and will be removed in Pillow 10 (2023-07-01). Use Resampling.BICUBIC instead.\n",
      "  transforms.Resize(224,Image.BICUBIC),\n",
      "/tmp/ipykernel_1183/3025049354.py:151: FutureWarning: Pass sr=16000, n_fft=400 as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel_basis = librosa.filters.mel(sr, n_fft, n_mels=num_mel_bins, fmin=fmin)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video created at: dir_exp_PlacesAudio/inferences/10/mm_SSL_TIE_PlacesAudio-lr1e-4-B128-SISA-SdT128-epoch33_val_10.mp4\n",
      "Success! Video file created: 120061 bytes\n",
      "Proceed to make the inference\n",
      "The model is in local\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ffmpeg version 5.1.2 Copyright (c) 2000-2022 the FFmpeg developers\n",
      "  built with gcc 11.3.0 (conda-forge gcc 11.3.0-19)\n",
      "  configuration: --prefix=/home/albert/miniconda3/envs/ssl-cpu --cc=/home/conda/feedstock_root/build_artifacts/ffmpeg_1674566204550/_build_env/bin/x86_64-conda-linux-gnu-cc --cxx=/home/conda/feedstock_root/build_artifacts/ffmpeg_1674566204550/_build_env/bin/x86_64-conda-linux-gnu-c++ --nm=/home/conda/feedstock_root/build_artifacts/ffmpeg_1674566204550/_build_env/bin/x86_64-conda-linux-gnu-nm --ar=/home/conda/feedstock_root/build_artifacts/ffmpeg_1674566204550/_build_env/bin/x86_64-conda-linux-gnu-ar --disable-doc --disable-openssl --enable-demuxer=dash --enable-hardcoded-tables --enable-libfreetype --enable-libfontconfig --enable-libopenh264 --enable-gnutls --enable-libmp3lame --enable-libvpx --enable-pthreads --enable-vaapi --enable-gpl --enable-libx264 --enable-libx265 --enable-libaom --enable-libsvtav1 --enable-libxml2 --enable-pic --enable-shared --disable-static --enable-version3 --enable-zlib --enable-libopus --pkg-config=/home/conda/feedstock_root/build_artifacts/ffmpeg_1674566204550/_build_env/bin/pkg-config\n",
      "  libavutil      57. 28.100 / 57. 28.100\n",
      "  libavcodec     59. 37.100 / 59. 37.100\n",
      "  libavformat    59. 27.100 / 59. 27.100\n",
      "  libavdevice    59.  7.100 / 59.  7.100\n",
      "  libavfilter     8. 44.100 /  8. 44.100\n",
      "  libswscale      6.  7.100 /  6.  7.100\n",
      "  libswresample   4.  7.100 /  4.  7.100\n",
      "  libpostproc    56.  6.100 / 56.  6.100\n",
      "Input #0, mov,mp4,m4a,3gp,3g2,mj2, from 'dir_exp_PlacesAudio/inferences/10/mm_SSL_TIE_PlacesAudio-lr1e-4-B128-SISA-SdT128-epoch33_val_10.mp4':\n",
      "  Metadata:\n",
      "    major_brand     : isom\n",
      "    minor_version   : 512\n",
      "    compatible_brands: isomiso2avc1mp41\n",
      "    encoder         : Lavf59.27.100\n",
      "  Duration: 00:00:10.00, start: 0.000000, bitrate: 96 kb/s\n",
      "  Stream #0:0[0x1](und): Video: h264 (High) (avc1 / 0x31637661), yuv420p(progressive), 224x224, 94 kb/s, 12.80 fps, 12.80 tbr, 16384 tbn (default)\n",
      "    Metadata:\n",
      "      handler_name    : VideoHandler\n",
      "      vendor_id       : [0][0][0][0]\n",
      "Guessed Channel Layout for Input Stream #1.0 : mono\n",
      "Input #1, wav, from 'dir_exp_PlacesAudio/audio/utterance_183783.wav':\n",
      "  Duration: 00:00:06.64, bitrate: 256 kb/s\n",
      "  Stream #1:0: Audio: pcm_s16le ([1][0][0][0] / 0x0001), 16000 Hz, mono, s16, 256 kb/s\n",
      "Stream mapping:\n",
      "  Stream #0:0 -> #0:0 (copy)\n",
      "  Stream #1:0 -> #0:1 (pcm_s16le (native) -> mp3 (libmp3lame))\n",
      "Press [q] to stop, [?] for help\n",
      "Output #0, mp4, to 'temp_output.mp4':\n",
      "  Metadata:\n",
      "    major_brand     : isom\n",
      "    minor_version   : 512\n",
      "    compatible_brands: isomiso2avc1mp41\n",
      "    encoder         : Lavf59.27.100\n",
      "  Stream #0:0(und): Video: h264 (High) (avc1 / 0x31637661), yuv420p(progressive), 224x224, q=2-31, 94 kb/s, 12.80 fps, 12.80 tbr, 16384 tbn (default)\n",
      "    Metadata:\n",
      "      handler_name    : VideoHandler\n",
      "      vendor_id       : [0][0][0][0]\n",
      "  Stream #0:1: Audio: mp3 (mp4a / 0x6134706D), 16000 Hz, mono, s16p\n",
      "    Metadata:\n",
      "      encoder         : Lavc59.37.100 libmp3lame\n",
      "frame=  128 fps=0.0 q=-1.0 Lsize=     139kB time=00:00:09.76 bitrate= 116.2kbits/s speed= 368x    \n",
      "video:115kB audio:20kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: 2.870779%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-Model Loaded\n",
      "Sample already downloaded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1183/3025049354.py:35: DeprecationWarning: BICUBIC is deprecated and will be removed in Pillow 10 (2023-07-01). Use Resampling.BICUBIC instead.\n",
      "  transforms.Resize(224,Image.BICUBIC),\n",
      "/tmp/ipykernel_1183/3025049354.py:151: FutureWarning: Pass sr=16000, n_fft=400 as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel_basis = librosa.filters.mel(sr, n_fft, n_mels=num_mel_bins, fmin=fmin)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video created at: dir_exp_PlacesAudio/inferences/10/mm_SSL_TIE_PlacesAudio-lr1e-4-B128-SISA-SdT128-epoch20_val_10.mp4\n",
      "Success! Video file created: 111194 bytes\n",
      "Proceed to make the inference\n",
      "The model is in local\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ffmpeg version 5.1.2 Copyright (c) 2000-2022 the FFmpeg developers\n",
      "  built with gcc 11.3.0 (conda-forge gcc 11.3.0-19)\n",
      "  configuration: --prefix=/home/albert/miniconda3/envs/ssl-cpu --cc=/home/conda/feedstock_root/build_artifacts/ffmpeg_1674566204550/_build_env/bin/x86_64-conda-linux-gnu-cc --cxx=/home/conda/feedstock_root/build_artifacts/ffmpeg_1674566204550/_build_env/bin/x86_64-conda-linux-gnu-c++ --nm=/home/conda/feedstock_root/build_artifacts/ffmpeg_1674566204550/_build_env/bin/x86_64-conda-linux-gnu-nm --ar=/home/conda/feedstock_root/build_artifacts/ffmpeg_1674566204550/_build_env/bin/x86_64-conda-linux-gnu-ar --disable-doc --disable-openssl --enable-demuxer=dash --enable-hardcoded-tables --enable-libfreetype --enable-libfontconfig --enable-libopenh264 --enable-gnutls --enable-libmp3lame --enable-libvpx --enable-pthreads --enable-vaapi --enable-gpl --enable-libx264 --enable-libx265 --enable-libaom --enable-libsvtav1 --enable-libxml2 --enable-pic --enable-shared --disable-static --enable-version3 --enable-zlib --enable-libopus --pkg-config=/home/conda/feedstock_root/build_artifacts/ffmpeg_1674566204550/_build_env/bin/pkg-config\n",
      "  libavutil      57. 28.100 / 57. 28.100\n",
      "  libavcodec     59. 37.100 / 59. 37.100\n",
      "  libavformat    59. 27.100 / 59. 27.100\n",
      "  libavdevice    59.  7.100 / 59.  7.100\n",
      "  libavfilter     8. 44.100 /  8. 44.100\n",
      "  libswscale      6.  7.100 /  6.  7.100\n",
      "  libswresample   4.  7.100 /  4.  7.100\n",
      "  libpostproc    56.  6.100 / 56.  6.100\n",
      "Input #0, mov,mp4,m4a,3gp,3g2,mj2, from 'dir_exp_PlacesAudio/inferences/10/mm_SSL_TIE_PlacesAudio-lr1e-4-B128-SISA-SdT128-epoch20_val_10.mp4':\n",
      "  Metadata:\n",
      "    major_brand     : isom\n",
      "    minor_version   : 512\n",
      "    compatible_brands: isomiso2avc1mp41\n",
      "    encoder         : Lavf59.27.100\n",
      "  Duration: 00:00:10.00, start: 0.000000, bitrate: 88 kb/s\n",
      "  Stream #0:0[0x1](und): Video: h264 (High) (avc1 / 0x31637661), yuv420p(progressive), 224x224, 87 kb/s, 12.80 fps, 12.80 tbr, 16384 tbn (default)\n",
      "    Metadata:\n",
      "      handler_name    : VideoHandler\n",
      "      vendor_id       : [0][0][0][0]\n",
      "Guessed Channel Layout for Input Stream #1.0 : mono\n",
      "Input #1, wav, from 'dir_exp_PlacesAudio/audio/utterance_183783.wav':\n",
      "  Duration: 00:00:06.64, bitrate: 256 kb/s\n",
      "  Stream #1:0: Audio: pcm_s16le ([1][0][0][0] / 0x0001), 16000 Hz, mono, s16, 256 kb/s\n",
      "Stream mapping:\n",
      "  Stream #0:0 -> #0:0 (copy)\n",
      "  Stream #1:0 -> #0:1 (pcm_s16le (native) -> mp3 (libmp3lame))\n",
      "Press [q] to stop, [?] for help\n",
      "Output #0, mp4, to 'temp_output.mp4':\n",
      "  Metadata:\n",
      "    major_brand     : isom\n",
      "    minor_version   : 512\n",
      "    compatible_brands: isomiso2avc1mp41\n",
      "    encoder         : Lavf59.27.100\n",
      "  Stream #0:0(und): Video: h264 (High) (avc1 / 0x31637661), yuv420p(progressive), 224x224, q=2-31, 87 kb/s, 12.80 fps, 12.80 tbr, 16384 tbn (default)\n",
      "    Metadata:\n",
      "      handler_name    : VideoHandler\n",
      "      vendor_id       : [0][0][0][0]\n",
      "  Stream #0:1: Audio: mp3 (mp4a / 0x6134706D), 16000 Hz, mono, s16p\n",
      "    Metadata:\n",
      "      encoder         : Lavc59.37.100 libmp3lame\n",
      "frame=  128 fps=0.0 q=-1.0 Lsize=     130kB time=00:00:09.76 bitrate= 108.9kbits/s speed= 197x    \n",
      "video:106kB audio:20kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: 3.029763%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-Model Loaded\n",
      "Sample already downloaded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1183/3025049354.py:35: DeprecationWarning: BICUBIC is deprecated and will be removed in Pillow 10 (2023-07-01). Use Resampling.BICUBIC instead.\n",
      "  transforms.Resize(224,Image.BICUBIC),\n",
      "/tmp/ipykernel_1183/3025049354.py:151: FutureWarning: Pass sr=16000, n_fft=400 as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel_basis = librosa.filters.mel(sr, n_fft, n_mels=num_mel_bins, fmin=fmin)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video created at: dir_exp_PlacesAudio/inferences/10/mm_SSL_TIE_PlacesAudio-lr1e-4-B128-S2Ms1571-SdT128-epoch20_val_10.mp4\n",
      "Success! Video file created: 89602 bytes\n",
      "Proceed to make the inference\n",
      "The model is in local\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ffmpeg version 5.1.2 Copyright (c) 2000-2022 the FFmpeg developers\n",
      "  built with gcc 11.3.0 (conda-forge gcc 11.3.0-19)\n",
      "  configuration: --prefix=/home/albert/miniconda3/envs/ssl-cpu --cc=/home/conda/feedstock_root/build_artifacts/ffmpeg_1674566204550/_build_env/bin/x86_64-conda-linux-gnu-cc --cxx=/home/conda/feedstock_root/build_artifacts/ffmpeg_1674566204550/_build_env/bin/x86_64-conda-linux-gnu-c++ --nm=/home/conda/feedstock_root/build_artifacts/ffmpeg_1674566204550/_build_env/bin/x86_64-conda-linux-gnu-nm --ar=/home/conda/feedstock_root/build_artifacts/ffmpeg_1674566204550/_build_env/bin/x86_64-conda-linux-gnu-ar --disable-doc --disable-openssl --enable-demuxer=dash --enable-hardcoded-tables --enable-libfreetype --enable-libfontconfig --enable-libopenh264 --enable-gnutls --enable-libmp3lame --enable-libvpx --enable-pthreads --enable-vaapi --enable-gpl --enable-libx264 --enable-libx265 --enable-libaom --enable-libsvtav1 --enable-libxml2 --enable-pic --enable-shared --disable-static --enable-version3 --enable-zlib --enable-libopus --pkg-config=/home/conda/feedstock_root/build_artifacts/ffmpeg_1674566204550/_build_env/bin/pkg-config\n",
      "  libavutil      57. 28.100 / 57. 28.100\n",
      "  libavcodec     59. 37.100 / 59. 37.100\n",
      "  libavformat    59. 27.100 / 59. 27.100\n",
      "  libavdevice    59.  7.100 / 59.  7.100\n",
      "  libavfilter     8. 44.100 /  8. 44.100\n",
      "  libswscale      6.  7.100 /  6.  7.100\n",
      "  libswresample   4.  7.100 /  4.  7.100\n",
      "  libpostproc    56.  6.100 / 56.  6.100\n",
      "Input #0, mov,mp4,m4a,3gp,3g2,mj2, from 'dir_exp_PlacesAudio/inferences/10/mm_SSL_TIE_PlacesAudio-lr1e-4-B128-S2Ms1571-SdT128-epoch20_val_10.mp4':\n",
      "  Metadata:\n",
      "    major_brand     : isom\n",
      "    minor_version   : 512\n",
      "    compatible_brands: isomiso2avc1mp41\n",
      "    encoder         : Lavf59.27.100\n",
      "  Duration: 00:00:10.00, start: 0.000000, bitrate: 71 kb/s\n",
      "  Stream #0:0[0x1](und): Video: h264 (High) (avc1 / 0x31637661), yuv420p(progressive), 224x224, 69 kb/s, 12.80 fps, 12.80 tbr, 16384 tbn (default)\n",
      "    Metadata:\n",
      "      handler_name    : VideoHandler\n",
      "      vendor_id       : [0][0][0][0]\n",
      "Guessed Channel Layout for Input Stream #1.0 : mono\n",
      "Input #1, wav, from 'dir_exp_PlacesAudio/audio/utterance_183783.wav':\n",
      "  Duration: 00:00:06.64, bitrate: 256 kb/s\n",
      "  Stream #1:0: Audio: pcm_s16le ([1][0][0][0] / 0x0001), 16000 Hz, mono, s16, 256 kb/s\n",
      "Stream mapping:\n",
      "  Stream #0:0 -> #0:0 (copy)\n",
      "  Stream #1:0 -> #0:1 (pcm_s16le (native) -> mp3 (libmp3lame))\n",
      "Press [q] to stop, [?] for help\n",
      "Output #0, mp4, to 'temp_output.mp4':\n",
      "  Metadata:\n",
      "    major_brand     : isom\n",
      "    minor_version   : 512\n",
      "    compatible_brands: isomiso2avc1mp41\n",
      "    encoder         : Lavf59.27.100\n",
      "  Stream #0:0(und): Video: h264 (High) (avc1 / 0x31637661), yuv420p(progressive), 224x224, q=2-31, 69 kb/s, 12.80 fps, 12.80 tbr, 16384 tbn (default)\n",
      "    Metadata:\n",
      "      handler_name    : VideoHandler\n",
      "      vendor_id       : [0][0][0][0]\n",
      "  Stream #0:1: Audio: mp3 (mp4a / 0x6134706D), 16000 Hz, mono, s16p\n",
      "    Metadata:\n",
      "      encoder         : Lavc59.37.100 libmp3lame\n",
      "frame=  128 fps=0.0 q=-1.0 Lsize=     109kB time=00:00:09.76 bitrate=  91.2kbits/s speed= 308x    \n",
      "video:85kB audio:20kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: 3.680982%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-Model Loaded\n",
      "Sample already downloaded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1183/3025049354.py:35: DeprecationWarning: BICUBIC is deprecated and will be removed in Pillow 10 (2023-07-01). Use Resampling.BICUBIC instead.\n",
      "  transforms.Resize(224,Image.BICUBIC),\n",
      "/tmp/ipykernel_1183/3025049354.py:151: FutureWarning: Pass sr=16000, n_fft=400 as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel_basis = librosa.filters.mel(sr, n_fft, n_mels=num_mel_bins, fmin=fmin)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video created at: dir_exp_PlacesAudio/inferences/10/mm_SSL_TIE_PlacesAudio-lr1e-4-B128-S2Ms1571-SdT128-epoch40_val_10.mp4\n",
      "Success! Video file created: 109471 bytes\n",
      "Proceed to make the inference\n",
      "The model is in local\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ffmpeg version 5.1.2 Copyright (c) 2000-2022 the FFmpeg developers\n",
      "  built with gcc 11.3.0 (conda-forge gcc 11.3.0-19)\n",
      "  configuration: --prefix=/home/albert/miniconda3/envs/ssl-cpu --cc=/home/conda/feedstock_root/build_artifacts/ffmpeg_1674566204550/_build_env/bin/x86_64-conda-linux-gnu-cc --cxx=/home/conda/feedstock_root/build_artifacts/ffmpeg_1674566204550/_build_env/bin/x86_64-conda-linux-gnu-c++ --nm=/home/conda/feedstock_root/build_artifacts/ffmpeg_1674566204550/_build_env/bin/x86_64-conda-linux-gnu-nm --ar=/home/conda/feedstock_root/build_artifacts/ffmpeg_1674566204550/_build_env/bin/x86_64-conda-linux-gnu-ar --disable-doc --disable-openssl --enable-demuxer=dash --enable-hardcoded-tables --enable-libfreetype --enable-libfontconfig --enable-libopenh264 --enable-gnutls --enable-libmp3lame --enable-libvpx --enable-pthreads --enable-vaapi --enable-gpl --enable-libx264 --enable-libx265 --enable-libaom --enable-libsvtav1 --enable-libxml2 --enable-pic --enable-shared --disable-static --enable-version3 --enable-zlib --enable-libopus --pkg-config=/home/conda/feedstock_root/build_artifacts/ffmpeg_1674566204550/_build_env/bin/pkg-config\n",
      "  libavutil      57. 28.100 / 57. 28.100\n",
      "  libavcodec     59. 37.100 / 59. 37.100\n",
      "  libavformat    59. 27.100 / 59. 27.100\n",
      "  libavdevice    59.  7.100 / 59.  7.100\n",
      "  libavfilter     8. 44.100 /  8. 44.100\n",
      "  libswscale      6.  7.100 /  6.  7.100\n",
      "  libswresample   4.  7.100 /  4.  7.100\n",
      "  libpostproc    56.  6.100 / 56.  6.100\n",
      "Input #0, mov,mp4,m4a,3gp,3g2,mj2, from 'dir_exp_PlacesAudio/inferences/10/mm_SSL_TIE_PlacesAudio-lr1e-4-B128-S2Ms1571-SdT128-epoch40_val_10.mp4':\n",
      "  Metadata:\n",
      "    major_brand     : isom\n",
      "    minor_version   : 512\n",
      "    compatible_brands: isomiso2avc1mp41\n",
      "    encoder         : Lavf59.27.100\n",
      "  Duration: 00:00:10.00, start: 0.000000, bitrate: 87 kb/s\n",
      "  Stream #0:0[0x1](und): Video: h264 (High) (avc1 / 0x31637661), yuv420p(progressive), 224x224, 85 kb/s, 12.80 fps, 12.80 tbr, 16384 tbn (default)\n",
      "    Metadata:\n",
      "      handler_name    : VideoHandler\n",
      "      vendor_id       : [0][0][0][0]\n",
      "Guessed Channel Layout for Input Stream #1.0 : mono\n",
      "Input #1, wav, from 'dir_exp_PlacesAudio/audio/utterance_183783.wav':\n",
      "  Duration: 00:00:06.64, bitrate: 256 kb/s\n",
      "  Stream #1:0: Audio: pcm_s16le ([1][0][0][0] / 0x0001), 16000 Hz, mono, s16, 256 kb/s\n",
      "Stream mapping:\n",
      "  Stream #0:0 -> #0:0 (copy)\n",
      "  Stream #1:0 -> #0:1 (pcm_s16le (native) -> mp3 (libmp3lame))\n",
      "Press [q] to stop, [?] for help\n",
      "Output #0, mp4, to 'temp_output.mp4':\n",
      "  Metadata:\n",
      "    major_brand     : isom\n",
      "    minor_version   : 512\n",
      "    compatible_brands: isomiso2avc1mp41\n",
      "    encoder         : Lavf59.27.100\n",
      "  Stream #0:0(und): Video: h264 (High) (avc1 / 0x31637661), yuv420p(progressive), 224x224, q=2-31, 85 kb/s, 12.80 fps, 12.80 tbr, 16384 tbn (default)\n",
      "    Metadata:\n",
      "      handler_name    : VideoHandler\n",
      "      vendor_id       : [0][0][0][0]\n",
      "  Stream #0:1: Audio: mp3 (mp4a / 0x6134706D), 16000 Hz, mono, s16p\n",
      "    Metadata:\n",
      "      encoder         : Lavc59.37.100 libmp3lame\n",
      "frame=  128 fps=0.0 q=-1.0 Lsize=     128kB time=00:00:09.76 bitrate= 107.5kbits/s speed= 403x    \n",
      "video:105kB audio:20kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: 3.086953%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-Model Loaded\n",
      "Sample already downloaded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1183/3025049354.py:35: DeprecationWarning: BICUBIC is deprecated and will be removed in Pillow 10 (2023-07-01). Use Resampling.BICUBIC instead.\n",
      "  transforms.Resize(224,Image.BICUBIC),\n",
      "/tmp/ipykernel_1183/3025049354.py:151: FutureWarning: Pass sr=16000, n_fft=400 as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel_basis = librosa.filters.mel(sr, n_fft, n_mels=num_mel_bins, fmin=fmin)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video created at: dir_exp_PlacesAudio/inferences/10/mm_SSL_TIE_PlacesAudio-lr1e-4-B128-S2Ms1571-SdT128-epoch51_val_10.mp4\n",
      "Success! Video file created: 116608 bytes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ffmpeg version 5.1.2 Copyright (c) 2000-2022 the FFmpeg developers\n",
      "  built with gcc 11.3.0 (conda-forge gcc 11.3.0-19)\n",
      "  configuration: --prefix=/home/albert/miniconda3/envs/ssl-cpu --cc=/home/conda/feedstock_root/build_artifacts/ffmpeg_1674566204550/_build_env/bin/x86_64-conda-linux-gnu-cc --cxx=/home/conda/feedstock_root/build_artifacts/ffmpeg_1674566204550/_build_env/bin/x86_64-conda-linux-gnu-c++ --nm=/home/conda/feedstock_root/build_artifacts/ffmpeg_1674566204550/_build_env/bin/x86_64-conda-linux-gnu-nm --ar=/home/conda/feedstock_root/build_artifacts/ffmpeg_1674566204550/_build_env/bin/x86_64-conda-linux-gnu-ar --disable-doc --disable-openssl --enable-demuxer=dash --enable-hardcoded-tables --enable-libfreetype --enable-libfontconfig --enable-libopenh264 --enable-gnutls --enable-libmp3lame --enable-libvpx --enable-pthreads --enable-vaapi --enable-gpl --enable-libx264 --enable-libx265 --enable-libaom --enable-libsvtav1 --enable-libxml2 --enable-pic --enable-shared --disable-static --enable-version3 --enable-zlib --enable-libopus --pkg-config=/home/conda/feedstock_root/build_artifacts/ffmpeg_1674566204550/_build_env/bin/pkg-config\n",
      "  libavutil      57. 28.100 / 57. 28.100\n",
      "  libavcodec     59. 37.100 / 59. 37.100\n",
      "  libavformat    59. 27.100 / 59. 27.100\n",
      "  libavdevice    59.  7.100 / 59.  7.100\n",
      "  libavfilter     8. 44.100 /  8. 44.100\n",
      "  libswscale      6.  7.100 /  6.  7.100\n",
      "  libswresample   4.  7.100 /  4.  7.100\n",
      "  libpostproc    56.  6.100 / 56.  6.100\n",
      "Input #0, mov,mp4,m4a,3gp,3g2,mj2, from 'dir_exp_PlacesAudio/inferences/10/mm_SSL_TIE_PlacesAudio-lr1e-4-B128-S2Ms1571-SdT128-epoch51_val_10.mp4':\n",
      "  Metadata:\n",
      "    major_brand     : isom\n",
      "    minor_version   : 512\n",
      "    compatible_brands: isomiso2avc1mp41\n",
      "    encoder         : Lavf59.27.100\n",
      "  Duration: 00:00:10.00, start: 0.000000, bitrate: 93 kb/s\n",
      "  Stream #0:0[0x1](und): Video: h264 (High) (avc1 / 0x31637661), yuv420p(progressive), 224x224, 91 kb/s, 12.80 fps, 12.80 tbr, 16384 tbn (default)\n",
      "    Metadata:\n",
      "      handler_name    : VideoHandler\n",
      "      vendor_id       : [0][0][0][0]\n",
      "Guessed Channel Layout for Input Stream #1.0 : mono\n",
      "Input #1, wav, from 'dir_exp_PlacesAudio/audio/utterance_183783.wav':\n",
      "  Duration: 00:00:06.64, bitrate: 256 kb/s\n",
      "  Stream #1:0: Audio: pcm_s16le ([1][0][0][0] / 0x0001), 16000 Hz, mono, s16, 256 kb/s\n",
      "Stream mapping:\n",
      "  Stream #0:0 -> #0:0 (copy)\n",
      "  Stream #1:0 -> #0:1 (pcm_s16le (native) -> mp3 (libmp3lame))\n",
      "Press [q] to stop, [?] for help\n",
      "Output #0, mp4, to 'temp_output.mp4':\n",
      "  Metadata:\n",
      "    major_brand     : isom\n",
      "    minor_version   : 512\n",
      "    compatible_brands: isomiso2avc1mp41\n",
      "    encoder         : Lavf59.27.100\n",
      "  Stream #0:0(und): Video: h264 (High) (avc1 / 0x31637661), yuv420p(progressive), 224x224, q=2-31, 91 kb/s, 12.80 fps, 12.80 tbr, 16384 tbn (default)\n",
      "    Metadata:\n",
      "      handler_name    : VideoHandler\n",
      "      vendor_id       : [0][0][0][0]\n",
      "  Stream #0:1: Audio: mp3 (mp4a / 0x6134706D), 16000 Hz, mono, s16p\n",
      "    Metadata:\n",
      "      encoder         : Lavc59.37.100 libmp3lame\n",
      "frame=  128 fps=0.0 q=-1.0 Lsize=     135kB time=00:00:09.76 bitrate= 113.4kbits/s speed= 332x    \n",
      "video:112kB audio:20kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: 2.941461%\n"
     ]
    }
   ],
   "source": [
    "local_dir_saving = \"dir_exp_PlacesAudio\"\n",
    "split = \"val\"\n",
    "samples_idx= 10\n",
    "models = [\n",
    "    # {\"model_name\": \"SSL_TIE_PlacesAudio-lr1e-5-2ly-B128-SISA-1GPUS-wV\", \"epoch\": 13},\n",
    "    # {\"model_name\": \"SSL_TIE_PlacesAudio_lr1e-5-2ly-B32-MISA\", \"epoch\": 100},\n",
    "    # {\"model_name\": \"SSL_TIE_PlacesAudio_lr1e-5-2ly-B128-MISA\", \"epoch\": 100},\n",
    "    # {\"model_name\": \"SSL_TIE_PlacesAudio_lr1e-5-2ly-B256-MISA\", \"epoch\": 100},\n",
    "    # {\"model_name\": \"SSL_TIE_PlacesAudio_lr1e-5-2ly-B128-SISA\", \"epoch\": 100},\n",
    "    # {\"model_name\": \"SSL_TIE_PlacesAudio_lr1e-3-2ly-B128-SISA\", \"epoch\": 39},\n",
    "    # {\"model_name\": \"SSL_TIE_PlacesAudio_lr1e-4-2ly-B32-MISA\", \"epoch\": 100},\n",
    "    {\"model_name\": \"SSL_TIE_PlacesAudio-lr1e-4-B128-SISA-SdT128\",\"epoch\": 33},\n",
    "    {\"model_name\": \"SSL_TIE_PlacesAudio-lr1e-4-B128-SISA-SdT128\",\"epoch\": 20},\n",
    "    {\"model_name\": \"SSL_TIE_PlacesAudio-lr1e-4-B128-S2Ms1571-SdT128\", \"epoch\": 20},\n",
    "    {\"model_name\": \"SSL_TIE_PlacesAudio-lr1e-4-B128-S2Ms1571-SdT128\", \"epoch\": 40},\n",
    "    {\"model_name\": \"SSL_TIE_PlacesAudio-lr1e-4-B128-S2Ms1571-SdT128\", \"epoch\": 51}\n",
    "    \n",
    "]\n",
    "\n",
    "for model in models:\n",
    "    model_weights_path = os.path.join(local_dir_saving, f'{model[\"model_name\"]}-epoch{model[\"epoch\"]}.pth.tar')\n",
    "    remote_path = f'/home/asantos/models/to_test/{model[\"model_name\"]}-epoch{model[\"epoch\"]}.pth.tar'\n",
    "    \n",
    "    # upload_file_to_cluster(local_path=model_weights_path, remote_path=remote_path)\n",
    "\n",
    "    inference_maker(\n",
    "        model_name=model[\"model_name\"],\n",
    "        epoch=model[\"epoch\"],\n",
    "        split=split,\n",
    "        sample_idx=sample_idx,\n",
    "        local_dir_saving=local_dir_saving\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ssl-cpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
