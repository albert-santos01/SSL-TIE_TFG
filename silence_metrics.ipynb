{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bce0912f",
   "metadata": {},
   "source": [
    "# Get pVA and negLoss for all the desired models\n",
    "Be aware that this is meant to get the pVA results for all the models that are inside in the cluster folder `/models/testing_things`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "389fdd59",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def extract_epoch_number(file_path):\n",
    "    \"\"\"\n",
    "    Extracts the epoch number from a model weight file path.\n",
    "\n",
    "    Args:\n",
    "        file_path (str): The file path of the model weight file.\n",
    "\n",
    "    Returns:\n",
    "        int: The epoch number if found, otherwise None.\n",
    "    \"\"\"\n",
    "    match = re.search(r'epoch(\\d+)', file_path)\n",
    "    if match:\n",
    "        return int(match.group(1))\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "afdddf67",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.utils import AverageMeter\n",
    "import time\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "from tqdm import tqdm\n",
    "from utils.util import *\n",
    "def get_silence_results(val_loader, model, device,epoch,args):\n",
    "    pVA_aud_meter = AverageMeter()\n",
    "    pVA_pad_meter = AverageMeter()\n",
    "    pVA_meter = AverageMeter()\n",
    "    sil_loss_meter = AverageMeter()\n",
    "\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "            \n",
    "            for idx, batch in tqdm(enumerate(val_loader), total=len(val_loader)):\n",
    "                image, spec, _, silence_vectors, nFrames = batch_unpacker(batch,args)\n",
    "\n",
    "                spec = Variable(spec).to(device, non_blocking=True)\n",
    "                image = Variable(image).to(device, non_blocking=True)\n",
    "                silence_vectors = Variable(silence_vectors).to(device,non_blocking=True)  if args.punish_silence else None\n",
    "                B = image.size(0)\n",
    "            \n",
    "                imgs_out, auds_out = model(image.float(), spec.float(), args, mode='val')\n",
    "\n",
    "                imgs_out = imgs_out.to('cpu').detach()\n",
    "                auds_out = auds_out.to('cpu').detach()\n",
    "                T = auds_out.size(2)\n",
    "\n",
    "                loss_sil, normal_mean = negAudio_loss(imgs_out,auds_out,silence_vectors)\n",
    "\n",
    "                pVA_aud, pVA_pad, pVA, _, _ = measure_pVA(silence_vectors, imgs_out, auds_out, nFrames)\n",
    "                \n",
    "                pVA_aud_meter.update(pVA_aud.item())\n",
    "                pVA_pad_meter.update(pVA_pad.item())\n",
    "                pVA_meter.update(pVA.item())\n",
    "\n",
    "                sil_loss_meter.update(loss_sil.item())\n",
    "                print(f\"Step: {idx}, pVA_aud: {pVA_aud.item()}, pVA_pad: {pVA_pad.item()}, pVA: {pVA.item()}, sil_loss: {loss_sil.item()}\")\n",
    "\n",
    "    if args.use_wandb:\n",
    "        wandb.log({\n",
    "            \"pVA_aud\": pVA_aud_meter.avg,\n",
    "            \"pVA_pad\": pVA_pad_meter.avg,\n",
    "            \"pVA\": pVA_meter.avg,\n",
    "            \"sil_loss\" : sil_loss_meter.avg, \n",
    "            \"epoch\": epoch\n",
    "        })\n",
    "\n",
    "    return pVA_aud_meter.avg, pVA_pad_meter.avg, pVA_meter.avg, sil_loss_meter.avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "89046bad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PlacesAudio split: VAL dataset size: 1000\n",
      "Creating Data loaders with 4 workers\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 1/5 [00:20<01:21, 20.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 0, pVA_aud: 0.0010573742911219597, pVA_pad: 0.0010049270931631327, pVA: 0.0020623013842850924, sil_loss: 0.007841695100069046\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 2/5 [00:26<00:35, 11.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 1, pVA_aud: 0.0009713502367958426, pVA_pad: 0.0010007037781178951, pVA: 0.0019720541313290596, sil_loss: 0.006450706627219915\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 3/5 [00:31<00:17,  8.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 2, pVA_aud: 0.0010618310188874602, pVA_pad: 0.001021187286823988, pVA: 0.00208301842212677, sil_loss: 0.007335518021136522\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 4/5 [00:37<00:07,  7.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 3, pVA_aud: 0.0010720578720793128, pVA_pad: 0.0010135413613170385, pVA: 0.0020855991169810295, sil_loss: 0.007299158722162247\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:43<00:00,  8.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 4, pVA_aud: 0.001038030837662518, pVA_pad: 0.0010427702218294144, pVA: 0.0020808009430766106, sil_loss: 0.006881620269268751\n",
      "Model: SSL_TIE_PlacesAudio-lr1e-4-B128-MISA-SdT128-Sil-O1-epoch44.pth.tar, pVA_aud: 0.0010401288513094188, pVA_pad: 0.0010166259482502938, pVA: 0.0020567547995597123, sil_loss: 0.007161739747971296\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                          model_name  pVA_aud   pVA_pad  \\\n",
      "0  SSL_TIE_PlacesAudio-lr1e-4-B128-MISA-SdT128-Si...  0.00104  0.001017   \n",
      "\n",
      "        pVA  sil_loss  epoch  \n",
      "0  0.002057  0.007162     44  \n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from datasets import PlacesAudio\n",
    "from torch.utils.data import  DataLoader\n",
    "import re\n",
    "# models\n",
    "models_path = \"testing_things\"\n",
    "results = {}\n",
    "\n",
    "sys.argv = ['script_name', '--order_3_tensor', '--spec_DAVENet', '--padval_spec', '-80',\n",
    "            '--placesAudio', '$DATA/PlacesAudio_400k_distro/metadata/',\n",
    "            '--n_threads', '4',\n",
    "            '--batch_size', '200',\n",
    "            '--punish_silence',\n",
    "            '--get_nFrames']\n",
    "\n",
    "\n",
    "args = get_arguments()\n",
    "\n",
    "# get the val_loader\n",
    "\n",
    "val_dataset = PlacesAudio(args.placesAudio + 'val.json', args,mode='val')\n",
    "\n",
    "print(\"Creating Data loaders with %d workers\" % args.n_threads)\n",
    "val_loader = DataLoader(val_dataset, batch_size=args.batch_size, shuffle=False,\\\n",
    "    num_workers=args.n_threads, drop_last=True, pin_memory=True)\n",
    "\n",
    "# Walk through the directory and get all files\n",
    "model_files = []\n",
    "for root, dirs, files in os.walk(models_path):\n",
    "    for model_path in files:\n",
    "        epoch = extract_epoch_number(model_path)\n",
    "        \n",
    "        #Load model\n",
    "        model, device = load_model(os.path.join(root,model_path),args)\n",
    "        \n",
    "        pVA_aud, pVA_pad, pVA, sil_loss = get_silence_results(val_loader, model, device, epoch, args)\n",
    "\n",
    "        #Store in results\n",
    "        results[model_path] = {\n",
    "            \"model_name\": model_path,  # Add model_name as a column\n",
    "            \"pVA_aud\": pVA_aud,\n",
    "            \"pVA_pad\": pVA_pad,\n",
    "            \"pVA\": pVA,\n",
    "            \"sil_loss\": sil_loss,\n",
    "            \"epoch\": epoch\n",
    "        }\n",
    "        print(f\"Model: {model_path}, pVA_aud: {pVA_aud}, pVA_pad: {pVA_pad}, pVA: {pVA}, sil_loss: {sil_loss}\")\n",
    "        \n",
    "\n",
    "    # Save results to a csv file\n",
    "    import pandas as pd\n",
    "\n",
    "    # Define the file path\n",
    "    file_path = 'testing_things/silence_results.csv'\n",
    "    # Create a DataFrame from the results dictionary\n",
    "    df = pd.DataFrame.from_dict(results, orient='index')\n",
    "\n",
    "    # Ensure model_name is the first column\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "    df = df[['model_name', 'pVA_aud', 'pVA_pad', 'pVA', 'sil_loss', 'epoch']]\n",
    "\n",
    "    # Save the DataFrame to a CSV file\n",
    "    df.to_csv(file_path, index=False)\n",
    "    # Print the DataFrame\n",
    "    print(df)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fd6d1fe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
