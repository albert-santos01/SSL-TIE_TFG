{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import PlacesAudio\n",
    "import sys\n",
    "from opts import get_arguments\n",
    "from utils import util as u\n",
    "from torch.utils.data import Dataset, DataLoader, dataset\n",
    "from torch.autograd import Variable\n",
    "import time\n",
    "import torch\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(val_loader, model, criterion, device, epoch, args):\n",
    "    batch_time = u.AverageMeter()\n",
    "    losses = u.AverageMeter()\n",
    "    acc_a_vAverage = u.AverageMeter()\n",
    "    acc_v_aAverage = u.AverageMeter() \n",
    "\n",
    "    tic = time.time()\n",
    "\n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        end = time.time()\n",
    "        for idx, (image, spec, audio, name, im) in tqdm(enumerate(val_loader), total=len(val_loader)):\n",
    "\n",
    "            spec = Variable(spec).to(device, non_blocking=True)\n",
    "            image = Variable(image).to(device, non_blocking=True)\n",
    "            B = image.size(0)\n",
    "\n",
    "            imgs_out, auds_out = model(image.float(), spec.float(), args, mode='val')\n",
    "                            \n",
    "            loss_cl,sims = u.infoNCE_loss(imgs_out,auds_out, args,return_S=True)\n",
    "            acc_v_a, acc_a_v =u.topk_accuracy(sims,k=5)\n",
    "\n",
    "            losses.update(loss_cl.item(), B)\n",
    "            acc_a_vAverage.update(acc_a_v)\n",
    "            acc_v_aAverage.update(acc_v_a)\n",
    "            batch_time.update(time.time() - end)\n",
    "            end = time.time()\n",
    "\n",
    "\n",
    "    print('Epoch: [{0}]\\t Eval '\n",
    "          'Loss: {loss.avg:.4f}  \\t T-epoch: {t:.2f} \\t'\n",
    "          .format(epoch, loss=losses, t=time.time()-tic))\n",
    "    return losses.avg, 0, 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/asantos/models/to_test/SSL_TIE_PlacesAudio-lr1e-5-2ly-B128-SISA-1GPUS-wV-epoch13.pth.tar'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Simulate command-line arguments for loading the model\n",
    "sys.argv = ['script_name', '--order_3_tensor', \n",
    "            '--simtype', 'MISA', \n",
    "            '--placesAudio', '$DATA/PlacesAudio_400k_distro/metadata/',\n",
    "            '--batch_size', \"32\", \n",
    "            '--n_threads', '0']\n",
    "\n",
    "args = get_arguments()\n",
    "\n",
    "models = [\n",
    "    {\"model_name\": \"SSL_TIE_PlacesAudio-lr1e-5-2ly-B128-SISA-1GPUS-wV\", \"epoch\": 13},\n",
    "    {\"model_name\": \"SSL_TIE_PlacesAudio_lr1e-5-2ly-B32-MISA\", \"epoch\": 100},\n",
    "    {\"model_name\": \"SSL_TIE_PlacesAudio_lr1e-5-2ly-B128-MISA\", \"epoch\": 100},\n",
    "    {\"model_name\": \"SSL_TIE_PlacesAudio_lr1e-5-2ly-B256-MISA\", \"epoch\": 100},\n",
    "    {\"model_name\": \"SSL_TIE_PlacesAudio_lr1e-5-2ly-B128-SISA\", \"epoch\": 100},\n",
    "    {\"model_name\": \"SSL_TIE_PlacesAudio_lr1e-3-2ly-B128-SISA\", \"epoch\": 39},\n",
    "    {\"model_name\": \"SSL_TIE_PlacesAudio_lr1e-4-2ly-B32-MISA\", \"epoch\": 100},\n",
    "]\n",
    "\n",
    "# remote_path = f'/home/asantos/models/to_test/{model[\"model_name\"]}-epoch{model[\"epoch\"]}.pth.tar'\n",
    "# u.load_model()\n",
    "model_path = models[0]\n",
    "model_path = f'/home/asantos/models/to_test/{model_path[\"model_name\"]}-epoch{model_path[\"epoch\"]}.pth.tar'\n",
    "model_path\n",
    "\n",
    "model,device = u.load_model(model_path,args)\n",
    "\n",
    "val_dataset = PlacesAudio(args.placesAudio + 'val.json', args,mode='val')\n",
    "\n",
    "val_loader = DataLoader(val_dataset, batch_size=args.batch_size, shuffle=False,\\\n",
    "        num_workers=args.n_threads, drop_last=True, pin_memory=True)\n",
    "\n",
    "validate(val_loader,model,None,device,epoch=100, args=args)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ssl-cpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
